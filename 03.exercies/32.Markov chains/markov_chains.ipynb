{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ext run_and_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with a file that lists the members of a set $\\mathit{words}$ of words, all made up of nothing but the 26 capital letters. In $\\mathit{words}$, 8 words contain the 3-gram (sequence of 3 symbols) ZEL:\n",
    "\n",
    "* 4 of those words contain ZELL (namely, DALZELL, GAZELLE, ROZELLE and ZELLERBACH);\n",
    "* 1 of those words contains ZELT (namely, TZELTAL);\n",
    "* 3 of those words end in ZEL (namely, DITZEL, HAZEL and RAPUNZEL).\n",
    "\n",
    "Hence\n",
    "\n",
    "* there is a probability of $\\frac{1}{2}$ that ZEL in a word in $\\mathit{words}$ be followed by L;\n",
    "* there is a probability of $\\frac{1}{8}$ that ZEL in a word in $\\mathit{words}$ be followed by T;\n",
    "* there is a probability of $\\frac{3}{8}$ that ZEL in a word in $\\mathit{words}$ actually ends the word.\n",
    "\n",
    "The same computations can be done for all possible $3$-grams, as well as for all possible $m$-grams with $m<3$ but requiring that they start a word as opposed to letting them occur anywhere in a word. Imagine that an \"end of word\" marker is appended to every word, so saying that a word $w$ ends in a sequence of letters $\\sigma$ is equivalent to saying that $\\sigma$ is followed by the end of word marker in $w$. One can then randomly generate a word $w$ as follows: \n",
    "\n",
    "* Randomly generate a letter, say $c_1$, following the probability that a word in $\\mathit{words}$ starts with $c_1$.\n",
    "* Randomly generate a letter or the end of word marker, say $c_2$, following the probability that a word in $\\mathit{words}$ that starts with $c_1$ actually starts with $c_1c_2$. In case $c_2$ is the end of word marker then $w = c_1$.\n",
    "* Otherwise, randomly generate a letter or the end of word marker, say $c_3$, following the probability that a word in $\\mathit{words}$ that starts with $c_1c_2$ actually starts with $c_1c_2c_3$. In case $c_3$ is the end of word marker then $w = c_1c_2$.\n",
    "* Otherwise, randomly generate a letter or the end of word marker, say $c_4$, following the probability that a word in $\\mathit{words}$ that contains $c_1c_2c_3$ actually contains $c_1c_2c_3c_4$. In case $c_4$ is the end of word marker then $w = c_1c_2c_3$.\n",
    "* Otherwise, randomly generate a letter or the end of word marker, say $c_5$, following the probability that a word in $\\mathit{words}$ that contains $c_2c_3c_4$ actually contains $c_2c_3c_4c_5$. In case $c_5$ is the end of word marker then $w = c_1c_2c_3c_4$.\n",
    "* Otherwise, randomly generate a letter or the end of word marker, say $c_6$, following the probability that a word in $\\mathit{words}$ that contains $c_3c_4c_5$ actually contains $c_3c_4c_5c_6$. In case $c_6$ is the end of word marker then $w = c_1c_2c_3c_4c_5$.\n",
    "* ...\n",
    "\n",
    "The randomly generated word $w$ could be infinite, with null probability. It has been generated following a kind of probability distribution known as a Markov chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program `markov_chain.py` that meets the following requirements.\n",
    "\n",
    "* The program prompts the user for a strictly positive integer $n$, a positive integer $\\mathit{nb\\_of\\_words}$ and an integer $\\mathit{for\\_seed}$, meant to represent the $n$ in $n$-gram, a number of words to be randomly generated as previously described, and a value to feed the `seed()` function of the `random` module to have control over the program outputs, respectively.\n",
    "* The program reads the contents of a file named `dictionary.txt`, supposed to be stored in the working directory, that contains uppercase words, one per line. Let $\\mathit{words}$ keep denoting the set of those words.\n",
    "* The program defines a function `computed_markov_chain(words, n)` that given as arguments $\\mathit{words}$ and $n$, returns a dictionary $\\mathit{markov\\_chain}$ whose keys are all $n$-grams that occur anywhere in at least one word in $\\mathit{words}$ and all $m$-grams for $m<n$ that occur at the beginning of at least one word in $\\mathit{words}$, and such that for a given key $\\sigma$, the value of $\\sigma$ is the list $L$ defined as follows. Let $c_1$, ..., $c_k$ be the symbols, either letters or end of word marker, such that:\n",
    "    * either $\\sigma$ is of length $n$ and at least one word in $\\mathit{words}$ contains $\\sigma$ followed by $c$,\n",
    "    * or $\\sigma$ is of length less than $n$ and at least one word in $\\mathit{words}$ starts with $\\sigma$ followed by $c$;\n",
    "    * $c_1$, ..., $c_k$ are lexicographically ordered, requesting that the end of word marker be greater than all letters.\n",
    "\n",
    "  Then $L=[(c_1,p_1),\\dots,(c_k,p_k)]$ where:\n",
    "  \n",
    "    * if $\\sigma$ is of length $n$ then $p_1$ is the probability that a word in $\\mathit{words}$ that contains $\\sigma$ be followed by $c_1$, whereas if $\\sigma$ is of length smaller than $n$ then $p_1$ is the probability that a word in $\\mathit{words}$ that starts with $\\sigma$ be followed by $c_1$.\n",
    "    * if $\\sigma$ is of length $n$ then $p_2$ is the probability that a word in $\\mathit{words}$ that contains $\\sigma$ be followed by $c_1$ or $c_2$, whereas if $\\sigma$ is of length smaller than $n$ then $p_2$ is the probability that a word in $\\mathit{words}$ that starts with $\\sigma$ be followed by $c_1$ or $c_2$.\n",
    "    * ...\n",
    "    * if $\\sigma$ is of length $n$ then $p_k$ is the probability that a word in $\\mathit{words}$ that contains $\\sigma$ be followed by one of $c_1$, $c_2$, ..., $c_k$, whereas if $\\sigma$ is of length smaller than $n$ then $p_k$ is the probability that a word in $\\mathit{words}$ that starts with $\\sigma$ be followed by one of $c_1$, $c_2$, ..., $c_k$; that probability is 1.\n",
    "    \n",
    "  For instance, `'ZEL'` should be one of $\\mathit{markov\\_chain}$'s keys, and the associated value should be `[('L',0.5), ('T',0.625), ('#',1)]` if `'#'` was chosen to denote the end of word marker.\n",
    "* The program defines a function `generate_word(words, markov_chain, n)`, that will be called after `computed_markov_chain()` will have been summoned with $\\mathit{words}$ and $n$ provided as arguments, returning the dictionary $\\mathit{markov\\_chain}$ previously described, and after the `seed()` function will have been summoned with the third user input provided as argument. When `generate_word()` is called with $\\mathit{nb\\_of\\_words}$, $\\mathit{markov\\_chain}$ and $n$ provided as argument, it randomly generates $\\mathit{nb\\_of\\_words}$ many words as previously described, moreover proceeding in a way that we explain based on one example, assuming that $n$ is equal to 3. Suppose that `generate_word()` has generated at least 3 letters of one of the $\\mathit{nb\\_of\\_words}$ many words to generate, say $w$. Suppose that the last 3 generated letters are Z, E and L. Then `generate_word()` calls `random()` to generate a number $r$ between 0 and 1.\n",
    "    * If $r$ is smaller than 0.5, namely, the probability that ZEL in a word in $\\mathit{words}$ be followed by L, then L is the next letter generated for $w$, which is not fully determined yet.\n",
    "    * Otherwise, if $r$ is smaller than 0.625, namely, the probability that ZEL in a word in $\\mathit{words}$ be followed by either L or T, then T is the next letter generated for $w$, which is not fully determined yet.\n",
    "    * Otherwise, $r$ is smaller than 1, namely, the probability that ZEL in a word in $\\mathit{words}$ be followed by either L or T or nothing, and $w$ is fully determined, consisting of all letters previouly generated for $w$.\n",
    "    \n",
    "  Eventually, `generate_word()` prints out the $\\mathit{nb\\_of\\_words}$ many words it has generated, one word per line, indicating for each word whether it has been invented because it is not a member of $\\mathit{words}$, or whether it has been rediscovered because it belongs to $\\mathit{words}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating 10 words using 1-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_test -i'1\\n10\\n0\\n' python3 markov_chains.py\n",
    "\n",
    "'What n to use for the n-grams? ', '1\\n',\n",
    "'How many words to generate? ', '10\\n',\n",
    "'What integer for the seed? ', '0\\n',\n",
    "'''\n",
    "Invented S\\n\n",
    "Invented GHINTHIN\\n\n",
    "Invented JES\\n\n",
    "Invented D\\n\n",
    "Invented WOULS\\n\n",
    "Invented PLANOUTITETIASS\\n\n",
    "Invented PANVEMSINE\\n\n",
    "Invented STALIVAPRMPOWINGULLEDERONCRY\\n\n",
    "Invented S\\n\n",
    "Invented TINSMPS\\n\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating 10 words using 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_test -i'2\\n10\\n20\\n' python3 markov_chains.py\n",
    "\n",
    "'What n to use for the n-grams? ', '2\\n',\n",
    "'How many words to generate? ', '10\\n',\n",
    "'What integer for the seed? ', '20\\n',\n",
    "'''\n",
    "Invented TROWEN\\n\n",
    "Invented SPEN\\n\n",
    "Invented BEWILIZES\\n\n",
    "Invented SNARACESS\\n\n",
    "Invented CABLUEMARECTORDULKE\\n\n",
    "Invented ST\\n\n",
    "Invented MED\\n\n",
    "Invented LE\\n\n",
    "Invented SCRASKTRISCOLIMATEIGNECALLABLED\\n\n",
    "Invented BELED\\n\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating 20 words using 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_test -i'3\\n20\\n40\\n' python3 markov_chains.py\n",
    "\n",
    "'What n to use for the n-grams? ', '3\\n',\n",
    "'How many words to generate? ', '20\\n',\n",
    "'What integer for the seed? ', '40\\n',\n",
    "'''\n",
    "Rediscovered INCH\\n\n",
    "Invented PARTIATE\\n\n",
    "Invented NITERE\\n\n",
    "Rediscovered BLUSH\\n\n",
    "Invented SHONED\\n\n",
    "Invented SMYTHED\\n\n",
    "Invented NOE\\n\n",
    "Invented BRIC\\n\n",
    "Invented UNTERS\\n\n",
    "Invented ABBINGS\\n\n",
    "Invented CAPTURIFIERS\\n\n",
    "Invented RADOPPING\\n\n",
    "Invented STUBA\\n\n",
    "Invented EXEL\\n\n",
    "Invented HIC\\n\n",
    "Invented NEIT\\n\n",
    "Invented AUTHFUL\\n\n",
    "Rediscovered MICA\\n\n",
    "Invented CENATIONTRACE\\n\n",
    "Rediscovered WASHING\\n\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating 20 words using 4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_test -i'4\\n20\\n75\\n' python3 markov_chains.py\n",
    "\n",
    "'What n to use for the n-grams? ', '4\\n',\n",
    "'How many words to generate? ', '20\\n',\n",
    "'What integer for the seed? ', '75\\n',\n",
    "'''\n",
    "Invented HEATLY\\n\n",
    "Rediscovered INTER\\n\n",
    "Rediscovered EDGE\\n\n",
    "Invented ETHANKLINING\\n\n",
    "Invented INSECTED\\n\n",
    "Rediscovered DIE\\n\n",
    "Rediscovered DILATION\\n\n",
    "Rediscovered HALVING\\n\n",
    "Invented REDISTICS\\n\n",
    "Invented ITALITY\\n\n",
    "Invented SPECTIVATOR\\n\n",
    "Rediscovered FULLY\\n\n",
    "Invented HORS\\n\n",
    "Invented HERED\\n\n",
    "Invented INDUCTIVELINOTYPICALLY\\n\n",
    "Rediscovered SKILL\\n\n",
    "Rediscovered RELATIVES\\n\n",
    "Invented ARCHESTNUT\\n\n",
    "Rediscovered WASH\\n\n",
    "Rediscovered SMOKABLE\\n\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating 20 words using 5-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_test -i'5\\n20\\n100\\n' python3 markov_chains.py\n",
    "\n",
    "'What n to use for the n-grams? ', '5\\n',\n",
    "'How many words to generate? ', '20\\n',\n",
    "'What integer for the seed? ', '100\\n',\n",
    "'''\n",
    "Invented BIRTHPLACEABLE\\n\n",
    "Rediscovered RECEIVING\\n\n",
    "Rediscovered TRANSACTION\\n\n",
    "Invented CONVERTISERS\\n\n",
    "Rediscovered MILQUETOAST\\n\n",
    "Rediscovered TRIGGER\\n\n",
    "Rediscovered SERVED\\n\n",
    "Invented MALIGNMENTS\\n\n",
    "Rediscovered LOCATE\\n\n",
    "Invented NOONTIMELESSLY\\n\n",
    "Invented BATISTICALLY\\n\n",
    "Rediscovered CLUNG\\n\n",
    "Rediscovered GEOFFREY\\n\n",
    "Rediscovered DUTIES\\n\n",
    "Rediscovered BENEFICIALLY\\n\n",
    "Rediscovered APPRENTICED\\n\n",
    "Rediscovered FLAIR\\n\n",
    "Invented MARRIERS\\n\n",
    "Rediscovered DRIFTING\\n\n",
    "Invented BANACHROME\\n\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
