{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not need to be executed if\n",
    "# ~/.ipython/profile_default/ipython_config.py\n",
    "# exists and contains:\n",
    "# c.InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('Illustrations.zip') as illustrations:\n",
    "    illustrations.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "from copy import copy, deepcopy\n",
    "from itertools import islice\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _definite logic program_ consists of _definite clauses_, that is, _universal closures_ of implications whose right hand sides are _atomic formulas_ and whose left hand sides are conjunctions of atomic formulas. Because a conjunction over an empty set of formulas is logically true, and an implication whose left hand side is a tautology is logically equivalent to its right hand side, atomic formulas, also known as _atoms_ or _facts_, are particular cases of definite clauses. Here is a definite logic program consisting of 13 definite clauses, the first 8 of which are facts:  \n",
    "\n",
    "$\\mathrm{father(bob,jack)}$  \n",
    "$\\mathrm{father(bob,sandra)}$  \n",
    "$\\mathrm{father(john,bob)}$  \n",
    "$\\mathrm{father(john,mary)}$  \n",
    "$\\mathrm{mother(jane,jack)}$  \n",
    "$\\mathrm{mother(jane,sandra)}$  \n",
    "$\\mathrm{mother(emily,bob)}$  \n",
    "$\\mathrm{mother(emily,mary)}$  \n",
    "$\\mathrm{\\forall X\\forall Y\\bigl(father(X,Y)\\rightarrow parent(X,Y)\\bigr)}$  \n",
    "$\\mathrm{\\forall X\\forall Y\\bigl(mother(X,Y)\\rightarrow parent(X,Y)\\bigr)}$  \n",
    "$\\mathrm{\\forall X\\forall Y\\bigl(parent(Y,X)\\wedge male(X)\\rightarrow son(X,Y)\\bigr)}$  \n",
    "$\\mathrm{\\forall X\\forall Y\\bigl(parent(Y,X)\\wedge female(X)\\rightarrow daughter(X,Y)\\bigr)}$  \n",
    "$\\mathrm{\\forall X\\forall Y\\forall Z\\bigl(male(X)\\wedge parent(Z,X)\\wedge parent(Z,Y)\\rightarrow brother(X,Y)\\bigr)}$  \n",
    "$\\mathrm{\\forall X\\forall Y\\forall Z\\bigl(parent(X,Z)\\wedge parent(Z,Y)\\rightarrow grandparent(X,Y)\\bigr)}$\n",
    "\n",
    "In English, this reads as:\n",
    "\n",
    "* Bob is a father of Jack and Sandra, John is a father of Bob and Mary, Jane is a mother of Jack and Sandra, Emily is a mother of Bob and Mary.\n",
    "* For all X, for all Y, if X is a father of Y then X is a parent of Y.\n",
    "* For all X, for all Y, if X is a mother of Y then X is a parent of Y.\n",
    "* For all X, for all Y, if Y is a parent of X and X is male then X is a son of Y.\n",
    "* For all X, for all Y, if Y is a parent of X and X is female then X is a daughter of Y.\n",
    "* For all X, for all Y, for all Z, if X is male, Z is a parent of X and Z is a parent of Y then X is is a brother of Y.\n",
    "* For all X, for all Y, for all Z, if X is a parent of Z and Z is a parent of Y, then X is a grandparent of Y.\n",
    "\n",
    "Note that the last two definite clauses are logically equivalent to:\n",
    "\n",
    "$\\mathrm{\\forall X\\forall Y\\Bigl(male(X)\\wedge\\exists Z\\bigl(parent(Z,X)\\wedge parent(Z,Y)\\bigr)\\rightarrow brother(X,Y)\\Bigr)}$  \n",
    "$\\mathrm{\\forall X\\forall Y\\Bigl(\\exists Z\\bigl(parent(X,Z)\\wedge parent(Z,Y)\\bigr)\\rightarrow grandparent(X,Y)\\Bigr)}$\n",
    "\n",
    "which reads as:\n",
    "\n",
    "* For all X, for all Y, if X is male and there exists Z such that Z is a parent of X and Z is a parent of Y, then X is is a brother of Y.\n",
    "* For all X, for all Y, if there exists Z such that X is a parent of Z and Z is a parent of Y, then X is a grandparent of Y.\n",
    "\n",
    "In Prolog, this definite logic program takes the form:\n",
    "\n",
    "father(bob, jack).  \n",
    "father(bob, sandra).  \n",
    "father(john, bob).  \n",
    "father(john, mary).  \n",
    "mother(jane, jack).  \n",
    "mother(jane, sandra).  \n",
    "mother(emily, bob).  \n",
    "mother(emily, mary).  \n",
    "parent(X, Y) :- father(X, Y).  \n",
    "parent(X, Y) :- mother(X, Y).  \n",
    "son(X, Y) :- parent(Y, X), male(X).   \n",
    "daughter(X, Y) :- parent(Y, X), female(X).  \n",
    "brother(X, Y) :- male(X), parent(Z, X), parent(Z, Y).  \n",
    "grandparent(X, Y) :- parent(X, Z), parent(Z, Y).\n",
    "\n",
    "An English reading of the definite clauses that are not facts that more closely follows this alternative syntax is:\n",
    "\n",
    "* For all X, for all Y, for X to be a parent of Y, it suffices that X be a father of Y.\n",
    "* For all X, for all Y, for X to be a parent of Y, it suffices that X be a mother of Y.\n",
    "* For all X, for all Y, for X to be a son of Y, it suffices that Y be a parent of X and that X be male.\n",
    "* For all X, for all Y, for X to be a daughter of Y, it suffices that Y be a parent of X and that X be female.\n",
    "* For all X, for all Y, for X to be a brother of Y, it suffices that X be male and that some Z exists that is a parent of both X and Y.\n",
    "* For all X, for all Y, for X to be a grandparent of Y, it suffices that some Z exists such that X is a parent of Z and Z is a parent of Y.\n",
    "\n",
    "The logical syntax suggests successive applications of _instantiation_ and _modus ponens_ to derive some atoms such as $\\mathrm{grandparent(john,jack)}$ from the given facts, in a _bottom up_ manner:\n",
    "\n",
    "* It is known that $\\mathrm{father(bob,jack)}$. Together with $\\mathrm{\\forall X\\forall Y\\bigl(father(X,Y)\\rightarrow parent(X,Y)\\bigr)}$, this implies that $\\mathrm{parent(bob,jack)}$.\n",
    "* It is known that $\\mathrm{father(john,bob)}$. Together with $\\mathrm{\\forall X\\forall Y\\bigl(father(X,Y)\\rightarrow parent(X,Y)\\bigr)}$, this implies that $\\mathrm{parent(john,bob)}$.\n",
    "* From $\\mathrm{\\forall X\\forall Y\\forall Z\\bigl(parent(X,Z)\\wedge parent(Z,Y)\\rightarrow grandparent(X,Y)\\bigr)}$ together with $\\mathrm{parent(john,bob)}$ and $\\mathrm{parent(bob,jack)}$, we infer that $\\mathrm{grandparent(john,jack)}$, ending the proof.\n",
    "\n",
    "The Prolog syntax suggests proving instances of some atomic formulas such as grandparent(john, jack) by proving instances of other atomic formulas that directly imply the latter, until nothing but given facts are eventually reached, in a _top down_ manner:\n",
    "\n",
    "* To prove grandparent(john, jack), it suffices to find a value for Z and prove both parent(john, Z) and parent(Z, jack).\n",
    "  * To find a value for Z and prove both parent(john, Z) and parent(Z, jack), it suffices to find a value for Z and either prove both father(john, Z) and parent(Z, jack) or prove both mother(john, Z) and parent(Z, jack).\n",
    "    * To find a value for Z and prove both father(john, Z) and parent(Z, jack), one can let Z be either bob or mary as indeed father(john, bob) and father(john, mary) are given, having to then prove either parent(bob, jack) or parent(mary, jack).\n",
    "      * To prove parent(bob, jack), it suffices to prove either father(bob, jack) or mother(bob, jack).\n",
    "        * Indeed, father(bob, jack) is given, ending the proof.\n",
    "         \n",
    "Note that the definite clauses that could be used were selected in the order in which they appeared. Suppose for instance that the clauses of the definite logic program that are not facts were listed as follows in Prolog form:\n",
    "\n",
    "parent(X, Y) :- mother(X, Y).  \n",
    "parent(X, Y) :- father(X, Y).  \n",
    "daughter(X, Y) :- parent(Y, X), female(X).  \n",
    "son(X, Y) :- parent(Y, X), male(X).   \n",
    "brother(X, Y) :- male(X), parent(Z, X), parent(Z, Y).  \n",
    "grandparent(X, Y) :- parent(X, Z), parent(Z, Y).\n",
    "\n",
    "Then the proof of grandparent(john, jack) would proceed as follows:\n",
    "\n",
    "* To prove grandparent(john, jack), it suffices to find a value for Z and prove both parent(john, Z) and parent(Z, jack).\n",
    "  * To find a value for Z and prove both parent(john, Z) and parent(Z, jack), it suffices to find a value for Z and either prove both mother(john, Z) and parent(Z, jack) or prove both father(john, Z) and parent(Z, jack).\n",
    "    * One cannot find a value for Z and prove mother(john, Z).\n",
    "    * To find a value for Z and prove both father(john, Z) and parent(Z, jack), one can let Z be either bob or mary as indeed father(john, bob) and father(john, mary) are given, having to then prove either parent(bob, jack) or parent(mary, jack).\n",
    "      * To prove parent(bob, jack), it suffices to prove either mother(bob, jack) or father(bob, jack).\n",
    "        * mother(bob, jack) cannot be proved.\n",
    "        * Indeed, father(bob, jack) is given, ending the proof.\n",
    "\n",
    "grandparent(john, jack) is a _closed_ formula: it contains no variable. Working with formulas that do contain variables, the approach that has been described lets us do more than prove: it lets us compute. Rather than talking about proving an atomic formula, one talks about _solving a goal_ or _answering a query_. For instance, solving the goal grandparent(john, X) lets us compute the instantiations of X that make the resulting formula a logical consequence of the logic program in its logical form. With the original ordering of the clauses, this proceeds as follows:\n",
    "\n",
    "* To solve grandparent(john, X), it suffices to find values for Z and Y and solve both parent(john, Z) and parent(Z, Y). One can then give X the value of Y.\n",
    "  * To find values for Z and Y and solve both parent(john, Z) and parent(Z, Y), it suffices to find values for Y and Y_0 and either solve both father(john, Y_0) and parent(Y_0, Y) or solve both mother(john, Y_0) and parent(Y_0, Y). One can then give X the value of Y.\n",
    "    * To find values for Y and Y_0 and solve both father(john, Y_0) and parent(Y_0, Y), one can let Y_0 be either bob or mary as indeed father(john, bob) and father(john, mary) are given, having to then solve either parent(bob, Y) or parent(mary, Y). One can then give X the value of Y.\n",
    "      * To find a value for Y and solve parent(bob, Y), it suffices to find a value for Y_0 and solve either father(bob, Y_0) or mother(bob, Y_0). One can then give X the value of Y_0.\n",
    "        * To find a value for Y_0 and solve father(bob, Y_0), one can let Y_0 be either jack or sandra. This yields two solutions to the original goal: X can take the value jack, or it can take the value sandra.\n",
    "        * One cannot find a value for Y_0 and solve mother(bob, Y_0).\n",
    "      * To find a value for Y and solve parent(mary, Y), it suffices to find a value for Y_0 and solve either father(mary, Y_0) or mother(mary, Y_0). One can then give X the value of Y_0.\n",
    "        * One cannot find a value for Y_0 and solve father(mary, Y_0).\n",
    "        * One cannot find a value for Y_0 and solve mother(mary, Y_0).\n",
    "  * One cannot find a value for Y_0 and solve mother(john, Y_0).\n",
    "\n",
    "Hence there are two and only two solutions to the goal grandparent(john,X): X equal to jack, and X equal to sandra.\n",
    "\n",
    "There is a bit of mystery in the preceding description in the way some variables are changed or new variables are introduced. This has to do with the fact that different occurrences of a given variable can be unrelated, which requires to sometimes rename variables and introduces somehow tricky technicalities:\n",
    "\n",
    "* Observe that the X in the goal grandparent(john, X) is unrelated to the X in the _rule_ (a more usual name for \"definite clause\" with Prolog notation) grandparent(X, Y) :- parent(X, Z), parent(Z, Y). If we want to let the goal interact with the rule, it is safe to rename all occurrences of X in the rule, using a new variable, say X_0: grandparent(X_0, Y) :- parent(X_0, Z), parent(Z, Y). We can then _unify_ the goal grandparent(john, X) and the _head_ of grandparent(X_0, Y) :- parent(X_0, Z), parent(Z, Y), namely, grandparent(X_0, Y), by replacing X_0 in grandparent(X_0, Y) by john and replacing X in grandparent(john, X) by Y (we could as well replace Y in grandparent(X_0, Y) by X, but the code to be developed later opts for the first alternative). Then the same replacements can be performed in the _body_ of grandparent(X_0, Y) :- parent(X_0, Z), parent(Z, Y), namely, parent(X_0, Z), parent(Z, Y), yielding the rule grandparent(john, Y) :- parent(john, Z), parent(Z, Y). This allows one to replace the goal grandparent(john, X) with the goals parent(john, Z) and parent(Z, Y), knowing that the values of Y that yield solutions to those goals are values of X that yield solutions to the original goal.\n",
    "* Observe that the Y in the goal parent(Z, Y), one of the two goals that we now have to solve, is unrelated to the Y in the rule parent(X, Y) :- father(X, Y). Also, the X in parent(X, Y) :- father(X, Y) is unrelated to the X in the original goal (grandparent(john, X)). If we want to let the other goal we now have to solve, parent(john, Z), interact with that rule, and let the X in the original goal alone, it is safe to rename all occurrences of Y in the rule, using a new variable, say Y_0, and rename all occurrences of X in the rule using a new variable, say X_0: parent(X_0, Y_0) :- father(X_0, Y_0). We can then unify the goal parent(john, Z) and the head of parent(X_0, Y_0) :- father(X_0, Y_0), by replacing X_0 in parent(X_0, Y_0) by john and replacing Z in parent(john, Z) by Y_0. Then the same replacements can be performed in the body of parent(X_0, Y_0) :- father(X_0, Y_0), yielding the rule parent(john, Y_0) :- father(john, Y_0). This allows one to replace the goal parent(john, Z) with the goal father(john, Y_0). But the Z in the goals parent(john, Z) and parent(Z, Y) are related, hence having replaced Z by Y_0 in parent(john, Z), we should replace Z by Y_0 in parent(Z, Y). So we goals we now have to solve are father(john, Y_0) and parent(Y_0, Y).\n",
    "\n",
    "The description of the search for solutions to the goal grandparent(john, X) has the structure of a tree. The following graphical representation of the description makes it particularly clear:\n",
    "\n",
    "<div><img src=\"Illustrations/tree_1.pdf\" width=\"600\"/></div>\n",
    "\n",
    "Observe that with the alternative listing considered above of the clauses of the definite logic program that are not facts, the description of the search for solutions to the goal grandparent(john, X) would be captured by the following tree:\n",
    "\n",
    "<div><img src=\"Illustrations/tree_2.pdf\" width=\"600\"/></div>\n",
    "\n",
    "\n",
    "Instead of starting with one goal, one can start with a sequence of (implicitly conjuncted) goals. For instance, if the logic program was extended with the fact female(sandra), then there would be two solutions to the goals grandparent(john, X), daughter(X, Y): X equal to sandra and Y equal to bob, and X equal to sandra and Y equal to jane.\n",
    "\n",
    "The atoms considered up to now are built from _predicate symbols_ (father, mother, parent, grandparent, male, female, son, daughter, brother), all of _arity_ 2, that is, all _binary_ predicate symbols, _constants_ (bob, jack, sandra, john, mary, jane, emily), and variables. Constant and variables are called _terms_. If we introduce _function symbols_ (of strictly positive arity, as constants are nothing but function symbols of arity 0, or _nullary_ function symbols), then we can build more complex terms. For instance, to represent lists of 0s and 1s, we can use:\n",
    "\n",
    "* 3 constants, o for 0, i for 1, and e for the empty list;\n",
    "* a binary function symbol (function symbol of arity 2) l, whose first argument is meant to be o or i and represent the first element of a nonempty list, and whose second argument is meant to be a term representing the rest of the list.\n",
    "\n",
    "For instance:\n",
    "\n",
    "* the term l(i, e) represents the list [1].\n",
    "* the term l(o, l(i, e)) represents the list [0, 1].\n",
    "* the term l(o, l(o, l(i, e))) represents the list [0, 0, 1].\n",
    "* the term l(i, l(o, l(o, l(i, e)))) represents the list [1, 0, 0, 1].\n",
    "* the term l(i, l(i, l(o, l(o, l(i, e))))) represents the list [1, 1, 0, 0, 1].\n",
    "\n",
    "Terms such as l(e, e), l(i, o), l(l(i, o), e) and l(l(i, e), l(i, e)) are syntactically valid, but are given no interpretation. \n",
    "\n",
    "We can then consider the logic program that defines the join (concatenation) function:\n",
    "\n",
    "join(e, X, X).  \n",
    "join(l(H, T), X, l(H, Y)) :- join(T, X, Y).\n",
    "\n",
    "This reads as:\n",
    "\n",
    "* Joining the empty list and a list X results in X itself.\n",
    "* To join a nonempty list and a list X, it suffices to join T and X, with T the list consisting of all elements of the first list except the first element H, resulting in a list Y, and put H at the front.\n",
    "\n",
    "This allows us to solve a goal such as join(l(i, l(i, l(o, e))), l(o, l(i, e)), X), with as unique solution X equal to l(i, l(i, l(o, l(o, l(i, e))))), reflecting the fact that joining [1, 1, 0] and [0, 1] results in the list [1, 1, 0, 0, 1]. But one can also solve a goal such as join(X, X, Y), so look for all possible ways to join a list with (a copy of) itself. There are infinitely many solutions, for instance:\n",
    "\n",
    "* X = e and Y = e: joining the empty list with itself results in the empty list.\n",
    "* X = l(o, e) and Y = l(o, l(o, e)): joining [0] with itself results in [0, 0].\n",
    "* X = l(i, e) and Y = l(i, l(i, e)): joining [1] with itself results in [1, 1].\n",
    "* X = l(i, l(o, e)) and Y = l(i, l(o, l(i, l(o, e)))): joining [1, 0] with itself results in [1, 0, 1, 0].\n",
    "\n",
    "Though they are correct, these solutions are not the most general ones, with the exception of the first one: all others are instances of more general solutions, that themselves contain variables:\n",
    "\n",
    "* X equal to l(H, e) and Y equal to l(H, l(H, e)): joining a list of the form [H] (where H is equal to 0 or 1) with itself results in the list [H, H].\n",
    "* X equal to l(H, l(H_0, e)) and Y equal to l(H, l(H_0, l(H, l(H_0, e)))): joining a list of the form [H, H_0] (where H and H_0 are independently equal to 0 or 1) with itself results in the list [H, H_0, H, H_0].\n",
    "\n",
    "By computing _most general unifiers_, one guarantees that nothing but most general solutions be generated. To solve the goal join(X, X, Y):\n",
    "\n",
    "* We first consider the fact join(e, X, X), change it to join(e, X_0, X_0), unify join(X, X, Y) and join(e, X_0, X_0) with the equalities X = e, X_0 = X and Y = X_0, from which we derive X = e, X_0 = e and Y = e, which yields the solution X = e and Y = e.\n",
    "* We then consider the rule join(l(H, T), X, l(H, Y)) :- join(T, X, Y), change it to join(l(H, T), X_0, l(H, Y_0)) :- join(T, X_0, Y_0), unify join(X, X, Y) and join(l(H, T), X_0, l(H, Y_0)) with the equalities X = l(H, T), X_0 = X and Y = l(H, Y_0), from which we derive X = l(H, T), X_0 = l(H, T) and Y = l(H, Y_0), having to now solve the goal join(T, l(H, T), Y_0).\n",
    "  * We first consider the fact join(e, X, X), change it to join(e, X_0, X_0), unify join(T, l(H, T), Y_0) and join(e, X_0, X_0) with the equalities T = e, X_0 = l(H, T) and Y_0 = X_0, from which we derive T = e, X_0 = l(H, e) and Y_0 = l(H, e), which together with X = l(H, T) and Y = l(H, Y_0), yields the solution X = l(H, e) and Y = l(H, l(H, e)).\n",
    "  * We then consider the rule join(l(H, T), X, l(H, Y)) :- join(T, X, Y), change it to join(l(H_0, T_0), X_0, l(H_0, Y_1)) :- join(T_0, X_0, Y_1), unify join(T, l(H, T), Y_0) and join(l(H_0, T_0), X_0, l(H_0, Y_1)) with the equalities T = l(H_0, T_0), X_0 = l(H, T) and Y_0 = l(H_0, Y_1), from which we derive T = l(H_0, T_0), X_0 = l(H, l(H_0, T_0)), Y_0 = l(H_0, Y_1), X = l(H, l(H_0, T_0)) and Y = l(H, l(H_0, Y_1)), having to now solve the goal join(T_0, l(H, l(H_0, T_0)), Y_1).\n",
    "    * We first consider the fact join(e, X, X), change it to join(e, X_0, X_0), unify join(T_0, l(H, l(H_0, T_0)), Y_1) and join(e, X_0, X_0) with the equalities T_0 = e, X_0 = l(H, l(H_0, T_0)) and Y_1 = X_0, from which we derive T_0 = e, X_0 = l(H, l(H_0, e)) and Y_1 = l(H, l(H_0, e)), which together with X = l(H, l(H_0, T_0)) and Y = l(H, l(H_0, Y_1)), yields the solution X = l(H, l(H_0, e)) and Y = l(H, l(H_0, l(H, l(H_0, e)))).\n",
    "    * We then consider the rule join(l(H, T), X, l(H, Y)) :- join(T, X, Y), change it to join(l(H_1, T), X_1, l(H_1, Y_0)) :- join(T, X_1, Y_0), unify join(T_0, l(H, l(H_0, T_0)), Y_1) and join(l(H_1, T), X_1, l(H_1, Y_0)) with the equalities T_0 = l(H_1, T), X_1 = l(H, l(H_0, T_0)) and Y_1 = l(H_1, Y_0), from which we derive T_0 = l(H_1, T), X_1 = l(H, l(H_0, l(H_1, T))), Y_1 = l(H_1, Y_0), X = l(H, l(H_0, l(H_1, T))) and Y = l(H, l(H_0, l(H_1, Y_0))), having to now solve the goal join(T, l(H, l(H_0, l(H_1, T))), Y_0).\n",
    "      * ...\n",
    "\n",
    "The search tree is infinite and looks as follows:\n",
    "\n",
    "<div><img src=\"Illustrations/tree_3.pdf\" width=\"600\"/></div>\n",
    "\n",
    "Observe that if the clauses that define the join function were listed in reverse order, that is, as\n",
    "\n",
    "join(l(H, T), X, l(H, Y)) :- join(T, X, Y).  \n",
    "join(e, X, X).\n",
    "\n",
    "then the search tree would look as follows:\n",
    "\n",
    "<div><img src=\"Illustrations/tree_4.pdf\" width=\"600\"/></div>\n",
    "\n",
    "So solving goals relative to a given definite logic program amounts to exploring a tree of the kind illustrated above; in fact, it is discovering, building the tree, and reporting solutions when reaching a _leaf_ associated with a solution. Two fundamental ways of exploring, or discovering, or building a tree are:\n",
    "\n",
    "* __Depth-first__: the leftmost unexplored _branch_ is explored all the way down, _backtracking_ up to the first embranchment where new branches have still not been explored.\n",
    "* __Breadth-first__: the _nodes_ are visited _level_ by level, from left to right on a given level.\n",
    "\n",
    "To illustrate and experiment, let us consider the tree below:\n",
    "\n",
    "<div><img src=\"Illustrations/tree_5.pdf\" width=\"400\"/></div>\n",
    "\n",
    "The `defaultdict` class from the `collections` module offers an elegant way to represent a tree. The code in the following cell works as follows.\n",
    "\n",
    "* `t = tree()` makes `t` denote a `defaultdict` object, say $t$.\n",
    "* `t['A']['B']['F'] = None` executes as follows. An attempt is made to access the key `'A'` of $t$, which does not exist and is therefore created, with as value what `tree()`, returns, namely, a new `defaultdict` object, say $t_1$. So `t['A']` evaluates to $t_1$. An attempt is made to access the key `'B'` of $t_1$, which does not exist and is therefore created, with as value what `tree()`, returns, namely, a new `defaultdict` object, say $t_2$. So `t['A']['B']` evaluates to $t_2$. An attempt is made to access the key `'F'` of $t_2$, which does not exist and is therefore created, with as value what `tree()`, returns, namely, a new `defaultdict` object, say $t_3$. So `t['A']['B']['C']` evaluates to $t_3$ and is then changed to `None`.\n",
    "* `t['A']['C']['G'] = None` executes as follows. An attempt is made to access the key `'A'` of $t$, which exists and  with `t['A']` evaluating to $t_1$. An attempt is made to access the key `'C'` of $t_1$, which does not exist and is therefore created and becomes the second key of $t_1$, with as value what `tree()`, returns, namely, a new `defaultdict` object, say $t_4$. So `t['A']['C']` evaluates to $t_4$. An attempt is made to access the key `'G'` of $t_4$, which does not exist and is therefore created, with as value what `tree()`, returns, namely, a new `defaultdict` object, say $t_5$. So `t['A']['C']['G']` evaluates to $t_5$ and is then changed to `None`.\n",
    "* ...\n",
    "\n",
    "The `pprint()` function from the `pprint` module makes it easier to see that `t` indeeds models the tree as intended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree():\n",
    "    return defaultdict(tree)\n",
    "\n",
    "t = tree()\n",
    "t['A']['B']['F'] = None\n",
    "t['A']['C']['G'] = None\n",
    "t['A']['C']['H']['K'] = None\n",
    "t['A']['C']['H']['L']['R'] = None\n",
    "t['A']['C']['H']['M'] = None\n",
    "t['A']['D'] = None\n",
    "t['A']['E']['I']['N'] = None\n",
    "t['A']['E']['I']['O']['S'] = None\n",
    "t['A']['E']['J']['P']['T'] = None\n",
    "t['A']['E']['J']['Q'] = None\n",
    "\n",
    "pprint(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this approach, a tree $t$ is modeled as a dictionary with a unique key, namely, the label of $t$'s __root__ (with `t` above as example, `'A'`), with as associated value, a dictionary that has as many keys as $t$'s root has __children__. That dictionary can be thought of as modeling a __forest__, namely, the collection of each __subtree__ of $t$ that has as root a child of $t$'s root (with `t` above as example, the subtrees rooted at `'B'`, `'C'`, `'D'` and `'E'`).\n",
    "\n",
    "A recursive function makes it easy to explore a tree and list all nodes in a depth-first manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursively_list_nodes_depth_first(t):\n",
    "    if t is None:\n",
    "        return\n",
    "    for node in t:\n",
    "        print(node, end=' ')\n",
    "        recursively_list_nodes_depth_first(t[node])\n",
    "        \n",
    "recursively_list_nodes_depth_first(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to list the __paths__ from the root of the tree in a depth-first manner, so output [A], [A, B], [A, B, F], [A, C], [A, C, G], [A, C, H]... rather than A, B, F, C, G, H..., with the help of a __stack__. It is easy to list either the nodes or the paths from the root of the tree in a breadth-first manner with the help of a __queue__. Stacks and queues are essentially lists with a limited set of methods:\n",
    "\n",
    "* For stacks, elements can be added and removed at one end (as plates brought to and removed from the top of a stack of plates, the sequence being viewed vertically rather than horizontally, with the end where the action takes place at the top). \n",
    "* For queues, elements can be added at one end and removed at the other end (as individuals queueing at a bus stop,   joining the queue at its back and leaving it, boarding the bus, at its front).\n",
    "\n",
    "    Python lists with their `append()` and `pop()` methods offer suitable implementations of stacks, as the time complexity of both operations is constant in amortised cost. On the other hand, Python lists do not offer an effective implementation of queues: removing the first element of a list and inserting an element at the beginning of a list both have time complexity that is linear in the length of the list. The `deque` class from the `collections` module combines the functionality of stacks and queues, as it has methods for adding and removing elements at boths end that all have constant time complexity (thanks to a data structure known as a __doubly linked list__). Let us first use a `dequeue` object as a stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively: stack = deque([])\n",
    "stack = deque(); stack\n",
    "stack.append(0); stack\n",
    "stack.append(1); stack\n",
    "stack.append(2); stack\n",
    "stack.pop(); stack # Two outputs\n",
    "stack.append(3); stack\n",
    "stack.append(4); stack\n",
    "stack.pop(); stack # Two outputs\n",
    "stack.pop(); stack # Two outputs\n",
    "stack.pop(); stack # Two outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can let a `deque` object $O$ model a queue in two ways, depending on how we match the ends of the queue with the ends of $O$. We can let the end of $O$ correspond to the front of the queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively: queue = deque([])\n",
    "queue = deque(); queue\n",
    "queue.appendleft(0); queue\n",
    "queue.appendleft(-1); queue\n",
    "queue.appendleft(-2); queue\n",
    "queue.pop(); queue # Two outputs\n",
    "queue.appendleft(-3); queue\n",
    "queue.appendleft(-4); queue\n",
    "queue.pop(); queue # Two outputs\n",
    "queue.pop(); queue # Two outputs\n",
    "queue.pop(); queue # Two outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can let the end of the `deque` object correspond to the back of the queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively: queue = deque([])\n",
    "queue = deque(); queue\n",
    "queue.append(0); queue\n",
    "queue.append(1); queue\n",
    "queue.append(2); queue\n",
    "queue.popleft(); queue # Two outputs\n",
    "queue.append(3); queue\n",
    "queue.append(4); queue\n",
    "queue.popleft(); queue # Two outputs\n",
    "queue.popleft(); queue # Two outputs\n",
    "queue.popleft(); queue # Two outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than appending elements to the back of a queue one after the other, we can prefer to in one sweep move, extend the back of the queue with all elements to append. In case the end of a `deque` object corresponds to the back of the queue it models, then the `extend()` method expectedly does the job. But in case the beginning of a `deque` object corresponds to the back of the queue, then the `extendleft()` method appropriately does the job too. Note how in the following cell, intending to append -1, then -2, then -3 on the left hand side, -3 indeed becomes the leftmost element, with -2 to its right, and -1 to the right of -2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = deque([0])\n",
    "queue.extend([1, 2, 3])\n",
    "queue.extendleft([-1, -2, -3])\n",
    "queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a recursive function that explores a tree and lists all nodes in a depth-first manner was easy because behind the scene, a stack manages all recursive calls (more generally, a stack manages all function calls). Let us now perform that exploration without taking advantage of recursion; instead, let us explicitly use a stack. Considering the dictionary `t` that models the tree $t$ as defined above, `iter(t)` creates an iterable that can yield all of `t`'s keys. Actually, `t` has only one key, namely, the label of $t$'s root (`'A'`), which can be generated with `next(iter(t))`; let `root` denote it. Then `t[root]` is a dictionary that has as many keys as $t$'s root has children (namely 4, labeled `'B'`, `'C'`, `'D'` and `'E'`). Since the keys of `t[root]` have been inserted into the dictionary starting with the label of the leftmost child of $t$'s root (`'B'`), and proceeding from left to right all the way to the label of the rightmost child of $t$'s root (`'E'`), `reversed(list(t[root]))` is an iterable that can yield those labels starting with the rightmost child of $t$'s root and ending with the leftmost child of $t$'s root (so in the order `'E'`, `'D'`, `'C'` and `'B'`). Adding to the top of a stack `(k, t[root][k])` with `k` yielded by `reversed(list(t[root]))`, we eventually get in the stack a pair of the form $(l_1, f_1)$ where $l_1$ is the label (`'E'`) of the rightmost child of $t$'s root and $f_1$ is the forest consisting of the trees rooted at that node (so the trees rooted at the nodes labeled `'I'` and `'J'`), and above in the stack a pair of the form $(l_2, f_2)$ where $l_2$ is the label (`'D'`) of the second rightmost child of $t$'s root and $f_2$ is an empty forest since that child has no child, and above in the stack a pair of the form $(l_3, f_3)$ where $l_3$ is the label (`'C'`) of the third rightmost child of $t$'s root and $f_3$ is the forest consisting of the trees rooted at that node (so the trees rooted at the nodes labeled `'G'` and `'H'`), and at the top of the stack a pair of the form $(l_4, f_4)$ where $l_4$ is the label (`'B'`) of the leftmost child of $t$'s root and $f_4$ is the forest consisting of the trees rooted at that node (so only one tree, rooted at the node labeled `'F'`). The last pair is indeed the pair that we want to pop first from the stack, since when exploring $t$ in a depth-first manner, the nodes in $f_4$ are enumerated before the nodes in $f_3$, that are enumerated before the nodes in $f_2$, that are enumerated before the nodes in $f_1$. The next cell implements a function that explores a tree depth-first search and calls it with `t` passed as argument. The cell is followed with a cell that traces execution of that function call, replacing the forests stored in the stack with the roots of their trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_nodes_depth_first(t):\n",
    "    root = next(iter(t))\n",
    "    roots_and_forests = deque([(root, t[root])])\n",
    "    while roots_and_forests:\n",
    "        root, forest = roots_and_forests.pop()\n",
    "        print(root, end=' ')\n",
    "        if forest:\n",
    "            roots_and_forests.extend((k, forest[k])\n",
    "                                          for k in reversed(list(forest))\n",
    "                                    )\n",
    "\n",
    "list_nodes_depth_first(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = next(iter(t))\n",
    "roots_and_forests = deque([(root, t[root])])\n",
    "print('Stack now (with trees changed to roots):\\n     ',\n",
    "      [(root, list(t[root]))]\n",
    "     )\n",
    "while roots_and_forests:\n",
    "    root, forest = roots_and_forests.pop()\n",
    "    print()\n",
    "    if forest:\n",
    "        print('Node output:', root, '\\t\\tRoots of forest to process:',\n",
    "              list(forest)\n",
    "             )\n",
    "    else:\n",
    "        print('Node output:', root, '\\t\\tEmpty forest')\n",
    "    if forest:\n",
    "        roots_and_forests.extend((k, forest[k])\n",
    "                                      for k in reversed(list(forest))\n",
    "                                )\n",
    "    print('Stack now (with trees changed to roots):\\n     ',\n",
    "          [(root, list(forest) if forest else None)\n",
    "                 for (root, forest) in roots_and_forests\n",
    "          ]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to modify the previous function to enumerate paths from the root of the tree rather than nodes: instead of storing nodes, we store paths, starting with the path that starts from and stops at the root of the tree (`['A']`) and creating extensions of a path $p$ with each of the children of the last node in $p$, unless that node is a leaf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_paths_depth_first(t):\n",
    "    root = next(iter(t))\n",
    "    paths_and_forests = deque([([root], t[root])])\n",
    "    while paths_and_forests:\n",
    "        path, forest = paths_and_forests.pop()\n",
    "        print(path)\n",
    "        if forest:\n",
    "            paths_and_forests.extend((path + [k], forest[k])\n",
    "                                          for k in reversed(list(forest))\n",
    "                                    )\n",
    "        \n",
    "list_paths_depth_first(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore a tree in a breadth-first manner and generate either nodes or paths, it suffices to modify the previous two functions, using a queue rather than a stack. Also, the left to right ordering of children of a given node should not be reversed. More precisely, the comments for `list_nodes_depth_first()` can be modified as follows (with `t` still denoting the dictionary that models the tree $t$ as defined above and `root` still denoting `next(iter(t))`, that is, the label of $t$'s root (`'A'`)). Adding to the back of a queue `(k, t[root][k])` with `k` yielded by `iter(t[root])`, we eventually get in the queue a pair of the form $(l_1, f_1)$ where $l_1$ is the label (`'B'`) of the leftmost child of $t$'s root and $f_1$ is the forest consisting of the trees rooted at that node (so only one tree, rooted at the node labeled `'F'`), and further in the back of the queue a pair of the form $(l_2, f_2)$ where $l_2$ is the label (`'C'`) of the second leftmost child of $t$'s root and $f_2$ is the forest consisting of the trees rooted at that node (so the trees rooted at the nodes labeled `'G'` and `'H'`), and further in the back of the queue a pair of the form $(l_3, f_3)$ where $l_3$ is the label (`'D'`) of the third leftmost child of $t$'s root and $f_3$ is an empty forest since that child has no child, and at the very back of the queue a pair of the form $(l_4, f_4)$ where $l_4$ is the label (`'E'`) of the rightmost child of $t$'s root and $f_4$ is the forest consisting of the trees rooted at that node (so the trees rooted at the nodes labeled `'I'` and `'J'`). The first pair is indeed the pair that we want to come to the front of the queue and be removed before all others, since when exploring $t$ in a breadth-first manner, the nodes on a given level should be enumerated from left to right. The function `list_nodes_depth_first()` is modified into the function `list_nodes_breadth_first()` in the next cell, in which the function is then called with `t` passed as argument. The cell is followed with a cell that traces execution of that function call, replacing the forests stored in the queue with the roots of their trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_nodes_breadth_first(t):\n",
    "    root = next(iter(t))\n",
    "    roots_and_forests = deque([(root, t[root])])\n",
    "    while roots_and_forests:\n",
    "        root, forest = roots_and_forests.pop()\n",
    "        print(root, end=' ')\n",
    "        if forest:\n",
    "            roots_and_forests.extendleft(forest.items())\n",
    "\n",
    "list_nodes_breadth_first(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = next(iter(t))\n",
    "roots_and_forests = deque([(root, t[root])])\n",
    "print('Queue now (with trees changed to roots):\\n     ',\n",
    "      [(root, list(t[root]))]\n",
    "     )\n",
    "while roots_and_forests:\n",
    "    root, forest = roots_and_forests.pop()\n",
    "    print()\n",
    "    if forest:\n",
    "        print('Node output:', root, '\\t\\tRoots of forest to process:',\n",
    "              list(forest)\n",
    "             )\n",
    "    else:\n",
    "        print('Node output:', root, '\\t\\tEmpty forest')\n",
    "    if forest:\n",
    "        roots_and_forests.extendleft(forest.items())\n",
    "    print('Queue now (with trees changed to roots):\\n     ',\n",
    "          [(root, list(forest) if forest else None)\n",
    "                 for (root, forest) in roots_and_forests\n",
    "          ]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`list_paths_depth_first()` is modified into `list_paths_breadth_first()` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_paths_breadth_first(t):\n",
    "    root = next(iter(t))\n",
    "    paths_and_forests = deque([([root], t[root])])\n",
    "    while paths_and_forests:\n",
    "        path, forest = paths_and_forests.pop()\n",
    "        print(path)\n",
    "        if forest:\n",
    "            paths_and_forests.extendleft((path + [k], forest[k])\n",
    "                                              for k in forest\n",
    "                                        )\n",
    "        \n",
    "list_paths_breadth_first(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting back to both trees for the goal grandparent(john, X):\n",
    "\n",
    "* Exploring the first tree in a depth-first manner yields both solutions fastest, after which the rest of the exploration is \"for nothing\".\n",
    "* Exploring the second tree in a depth-first manner yields both solutions at the very end.\n",
    "* Exploring the first and second trees in a breadth-first manner yields both solutions at the very end.\n",
    "\n",
    "Getting back to both trees for the goal join(X, X, Y):\n",
    "\n",
    "* Exploring the first tree in a depth-first or breadth-first manner makes no difference; the solutions are generated one by one, and the exploration would have to be interrupted at some point as it could go on forever and produce infinitely many solutions.\n",
    "* Exploring the second tree in a breadth-first manner is hardly different to exploring the first tree in a breadth-first manner, one node being visited before rather than after the production of a given solution.\n",
    "* Exploring the second tree in a depth-first manner traps the search in an infinite descent along the leftmost branch, with no solution being ever produced.\n",
    "\n",
    "Solving goals relative to a given definite logic program by a breadth-first exploration of the associated search tree is a __complete__ proof procedure: every solution is eventually produced. This is an immediate consequence of the fact that such a tree is __finitely branching__. On the other hand, as we have just observed, a depth-first exploration does not offer a complete proof procedure. Usually, Prolog's proof engine implements a depth-first search, hence an incomplete proof procedure: it expects users to properly order the rules that make up the program, and to properly order in a rule the atoms that make up its body, so that the search trees associated with goals of interest have \"a good shape\" and make depth-first search a most efficient procedure. We will write a Prolog interpreter where we can chose to explore a search tree either in a depth-first or in a breadth-first manner (the difference is minor and essentially relies on using either a stack or a queue in pretty much the same way, as we have previously observed). The exploration of a search tree is the last part of the work the interpreter has to do. First, we need to be able to parse the rules that make up a definite logic program, as well as perform a number of operations such as separate head and body from a rule, identify which variables occur in an atom, perform substitution of variables by terms in an atom, etc. We first define a helper function to consistently extend a dictionary with a sequence of key-value pairs, making use of the `setdefault` method of the `dict` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = {}\n",
    "\n",
    "D.setdefault('A'), D\n",
    "D.setdefault('A', 1), D\n",
    "D.setdefault('B', 1), D\n",
    "D.setdefault('B'), D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistently_add_to(mapping, *key_values):\n",
    "    for (key, value) in key_values:\n",
    "        if mapping.setdefault(key, value) != value:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "D = {}\n",
    "\n",
    "consistently_add_to(D, ('A', 1)), D\n",
    "consistently_add_to(D, ('A', 1)), D\n",
    "consistently_add_to(D, ('A', 2)), D\n",
    "consistently_add_to(D, ('B', 2), ('C', 3)), D\n",
    "consistently_add_to(D, ('A', 1), ('C', 3), ('D', 4)), D\n",
    "consistently_add_to(D, ('B', 3), ('E', 5)), D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define three classes, `Expression`, `Term` and `Atom`, with `Term` and `Atom` inheriting from `Expression`, considering that terms and atoms are two kinds of expressions.\n",
    "\n",
    "Generalising on the examples previously examined:\n",
    "\n",
    "* an atom is built from an $n$-ary predicate symbol ($n\\in\\mathbf N$) and $n$ terms;\n",
    "* a term is a variable or is built from an $n$-ary function symbol ($n\\in\\mathbf N$) and $n$ terms.\n",
    "\n",
    "So the outermost symbol in an atom is a predicate symbol while all other symbols are function symbols or variables; all symbols in a term are function symbols or variables. Prolog function symbols, predicate symbols and variables are built from alphanumeric characters and underscores, with function and predicate symbols starting with lowercase letters, and variables starting with uppercase letters or underscores.\n",
    "\n",
    "Trees are most appropriate to represent expressions. To give `Expression` objects the structure of trees that represent expressions, we use two attributes, `root` and `children`. Given an object $O$ of classs `Expression` meant to represent an expression $E$:\n",
    "\n",
    "* the value of `root` for $O$ will be set to the string that denotes $E$'s outermost symbol $s$ (a predicate symbol if $E$ is an atom, a function symbol if $E$ is a term);\n",
    "* if $n$ is $s$'s arity, the value of `children` for $O$ will be set to a list of length $n$ consisting of $n$ `Expression` objects, that represent the $n$ terms that are the arguments to $s$ in $E$, listed from left to right (so the list is empty in case $E$ is a nullary predicate symbol, a constant, or a variable).\n",
    "\n",
    "`Expression` objects will be created by parsing strings, giving atoms and terms a tree structure. We implement `__str__()` in `Expression` for what can be seen as the reverse operation: get the (properly formatted) string from the representing tree. When testing `__str__()` below, we define `Expression` objects \"by hand\"; parsing methods will be defined later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expression:\n",
    "    def __init__(self, root, children=[]):\n",
    "        self.root = root\n",
    "        self.children = children\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.root if not self.children\\\n",
    "                         else ''.join((self.root, '(',\n",
    "                                      ', '.join(str(child)\n",
    "                                                    for child in self.children\n",
    "                                               ), ')'\n",
    "                                      )\n",
    "                                     )\n",
    "\n",
    "\n",
    "class Term(Expression):\n",
    "    class TermError(Exception):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Atom(Expression):\n",
    "    class AtomError(Exception):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bob: constant\n",
    "print(Term('bob'))\n",
    "# l: binary function symbol\n",
    "# H, T: variables\n",
    "print(Term('l', [Term('H'), Term('T')]))\n",
    "# l: binary function symbol\n",
    "# e: constant\n",
    "# H, T: variables\n",
    "print(Term('l', [Term('e'), Term('l', [Term('H'), Term('T')])]))\n",
    "\n",
    "print()\n",
    "\n",
    "# on: nullary predicate symbol\n",
    "print(Atom('on'))\n",
    "# happy: unary predicate symbol\n",
    "# john: constant\n",
    "print(Atom('happy', [Term('john')]))\n",
    "# mother: binary predicate symbol\n",
    "# jane, sandra: constants\n",
    "print(Atom('mother', [Term('jane'), Term('sandra')]))\n",
    "# join: binary predicate symbol\n",
    "# l: binary function symbol\n",
    "# H, T, X, Y: variables\n",
    "print(Atom('join', [Term('l', [Term('H'), Term('T')]), Term('X'),\n",
    "                    Term('l', [Term('H'), Term('Y')])\n",
    "                   ]\n",
    "          )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we create a `Term` or an `Atom` object, we collect all its function symbols in the form of a dictionary, with symbols as keys and symbols' arities as values. The core of the work is performed by `consistently_add_to()`, with the help of an `Expression` method, `is_variable()`. The code checks that no function symbol is used with different arities in a term, and that the predicate and function symbols in an atom are different; that part of the code will be tested when testing the functions that parse strings and create `Term` or `Atom` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expression:\n",
    "    def is_variable(self):\n",
    "        return self.root[0].isupper() or self.root[0] == '_' \n",
    "\n",
    "\n",
    "class Term(Expression, Term):\n",
    "    def __init__(self, root, children=[]):\n",
    "        super().__init__(root, children)\n",
    "        self.function_symbols = {} if self.is_variable()\\\n",
    "                                   else {root: len(self.children)}\n",
    "        for child in self.children:\n",
    "            if not consistently_add_to(self.function_symbols,\n",
    "                                       *child.function_symbols.items()\n",
    "                                      ):\n",
    "                raise Term.TermError('Function symbol used with different '\n",
    "                                     f'arities in {self}'\n",
    "                                    )\n",
    "\n",
    "\n",
    "class Atom(Expression, Atom):\n",
    "    def __init__(self, root, children=[]):\n",
    "        super().__init__(root, children)\n",
    "        self.function_symbols = {}\n",
    "        for child in self.children:\n",
    "            if not consistently_add_to(self.function_symbols,\n",
    "                                       *child.function_symbols.items()\n",
    "                                      ):\n",
    "                raise Term.TermError('Function symbol used with different '\n",
    "                                     f'arities in {self}'\n",
    "                                    )\n",
    "        if self.root in self.function_symbols:\n",
    "            raise Atom.AtomError('Predicate symbol also function symbol '\n",
    "                                 f'in {self}'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Term('bob').function_symbols\n",
    "Term('l', [Term('H'), Term('T')]).function_symbols\n",
    "Term('l', [Term('e'), Term('l', [Term('H'), Term('T')])]).function_symbols\n",
    "Atom('on').function_symbols\n",
    "Atom('happy', [Term('john')]).function_symbols\n",
    "Atom('mother', [Term('jane'), Term('sandra')]).function_symbols\n",
    "Atom('join', [Term('l', [Term('H'), Term('T')]), Term('X'),\n",
    "              Term('l', [Term('H'), Term('Y')])\n",
    "             ]\n",
    "    ).function_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is reasonable to embed the code that parses a string and creates an `Expression` object, and more specifically a `Term` or an `Atom` object, within the `Expression`, `Term` or `Atom` class. But such a piece of code does not naturally take the form of one of the classes' methods. Indeed, a method of any those classes is meant to operate on an object of the class, already created, with its `root` and `children` attributes, whereas the purpose of the code under discussion is precisely to create such an object. A natural design is to define a __static method__ or a __class method__. Such a method can be called from an object of the class where it is defined, but it can also be called from the class itself. The easiest way to defined such methods is to use the `staticmethod` and `classmethod` decorators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C:\n",
    "    @staticmethod\n",
    "    def a_static_method(*arguments):\n",
    "        print(arguments)\n",
    "        \n",
    "    @classmethod\n",
    "    def a_class_method(*arguments):\n",
    "        print(arguments)\n",
    "        \n",
    "C.a_static_method('Class is not an argument', 'of a static method')\n",
    "C().a_static_method('Class is not an argument', 'of a static method')\n",
    "\n",
    "print()\n",
    "\n",
    "C.a_class_method('Class is first argument', 'of a class method')\n",
    "C().a_class_method('Class is first argument', 'of a class method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse an atom or a term represented as a string, we will first get rid of all spaces in the string, if any, and convert the resulting string to a list $L$ of characters, from last character in the string to first character in the string, so that characters can be efficiently consumed by popping them off the end of the list, as opposed to removing them from the beginning of the list. Opening and closing parentheses and commas will need special processing. The rest is predicate and function symbols and variables, which will be dealt with thanks to a function, `parse_word()`. This function receives as argument what remains of $L$, assumed to be at the stage where a predicate or function symbol or a variable is to be parsed; so $L$ then ends in the characters that make up that predicate or function symbol or variable in reverse order; `parse_word()` consumes those characters from $L$ and returns the predicate or function symbol or the variable as a string. The function can be defined as a static method in the `Expression` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expression(Expression):\n",
    "    @staticmethod    \n",
    "    def parse_word(characters):\n",
    "        word = [characters.pop()]\n",
    "        while characters and (characters[-1].isalnum()\n",
    "                              or characters[-1] == '_'\n",
    "                             ):\n",
    "            word.append(characters.pop())\n",
    "        return ''.join(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = list(reversed('bob'.replace(' ', '')))\n",
    "characters\n",
    "Expression.parse_word(characters)\n",
    "characters\n",
    "\n",
    "print()\n",
    "\n",
    "characters = list(reversed('happy(  john  )'.replace(' ', '')))\n",
    "characters\n",
    "Expression.parse_word(characters)\n",
    "characters\n",
    "\n",
    "print()\n",
    "\n",
    "# Could be what remains to be parsed in \"join(l(H, T), X, l(H, Y))\"\n",
    "# after \"join(l(H, T), X, l(\" has been parsed already.\n",
    "characters = list(reversed('H,  Y))'.replace(' ', '')))\n",
    "characters\n",
    "Expression.parse_word(characters)\n",
    "characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let an atom or a term $E$ be given and let $L$ be the list of all nonspace characters in $E$ in reverse order. We will define in `Expression` two functions, `parse_subitem()` and `parse_subitem_sequence()`, meant to operate in a way that we now describe. To parse $E$ (possibly as a subexpression of a larger expression), the function `parse_subitem()` will be called with $L$ passed as argument. It will first check that $E$ indeed starts with (that is, $L$ indeed ends in) a character that can be the beginning of a predicate or function symbol or a variable and call `parse_word()`, passing $L$ as argument. If $E$ is a nullary predicate or function symbol or a variable, that predicate or function symbol or variable will be returned by `parse_word()` and $L$ will have become empty. Otherwise, $E$ is of the form $\\sigma(t_1,\\dots,t_n)$ for some nonzero $n\\in\\mathbf N$, predicate or function symbol $\\sigma$, and terms $t_1$, ..., $t_n$. Then `parse_word()` will return $\\sigma$, having consumed all characters that make up $\\sigma$; `parse_subitem()`, finding out that $L$ is not empty, will then check that $L$ indeeds ends in `(`, consume that character (that it, pop `(` off the end of $L$), and call `parse_subitem_sequence()`, passing $L$ as argument, whose purpose is to parse $t_1,\\dots, t_n$ and return a list with as members, the $n$ `Term` objects $o_1$, ..., $o_n$ that represent $t_1$, ..., $t_n$. At this stage, all characters occurring in $t_1$, ..., $t_n$ and the separating commas will have been consumed, and the only task left for `parse_subitem()` to complete will be to check that `)` is now the last symbol in $L$ (it should also be the only symbol in $L$ in case $E$ is the whole expression to parse, but that will not be up to `parse_subitem()` to check: `parse_subitem()` does not know whether it parses a whole expression or a subexpression of a larger expression), consume it, and create an `Atom` or a `Term` object whose `root` attribute should be set to $\\sigma$ and whose `children` attribute should be set to the list $[o_1,\\dots,o_n]$. Recall that `parse_subitem_sequence()` will have to parse $t_1,\\dots, t_n$. It will do so with a first call to `parse_subitem()` to create a `Term` object $o_1$ that represents $t_1$. It will then find out that $L$ now ends in a comma, consume it, and make a second call to `parse_subitem()` to create a `Term` object $o_2$ that represents $t_2$. Eventually, it will make a last call to `parse_subitem()` to create a `Term` object $o_n$ that represents $t_n$, find out that $L$ does not end in a comma, assume that the whole sequence has been successfully parsed, and return $[o_1,\\dots,o_n]$ to its caller (the original `parse_subitem()` call).\n",
    "\n",
    "Before we implement `parse_subitem()` and `parse_subitem_sequence()`, we define skeleton functions to illustrate how `parse_subitem()` and `parse_subitem_sequence()` are meant to call each other, and how characters are consumed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_subitem_skeleton(characters, depth=0):\n",
    "    print('  ' * depth, 'Start parsing subitem, characters left:',\n",
    "          ''.join(reversed(characters))\n",
    "         )\n",
    "    Expression.parse_word(characters)\n",
    "    if not characters or characters[-1] != '(':\n",
    "        print('  ' * depth, 'End parsing subitem, characters left:',\n",
    "              ''.join(reversed(characters))\n",
    "             )\n",
    "        return\n",
    "    # Popping (\n",
    "    characters.pop()\n",
    "    parse_subitem_sequence_skeleton(characters, depth + 1)\n",
    "    # Popping )\n",
    "    characters.pop()\n",
    "    print('  ' * depth, 'End parsing subitem, characters left:',\n",
    "          ''.join(reversed(characters))\n",
    "         )\n",
    "\n",
    "def parse_subitem_sequence_skeleton(characters, depth):\n",
    "    print('  ' * depth, 'Start parsing subitem sequence, characters left:',\n",
    "          ''.join(reversed(characters))\n",
    "         )\n",
    "    expressions = []\n",
    "    while True:\n",
    "        expressions.append(parse_subitem_skeleton(characters, depth + 1))\n",
    "        if characters[-1] != ',':\n",
    "            print('  ' * depth,\n",
    "                  'End parsing subitem sequence, characters left:',\n",
    "                  ''.join(reversed(characters))\n",
    "                 )\n",
    "            return\n",
    "        # Popping ,\n",
    "        characters.pop()\n",
    "        \n",
    "parse_subitem_skeleton(list(reversed('bob')))\n",
    "print()\n",
    "parse_subitem_skeleton(list(reversed('happy(john)')))\n",
    "print()\n",
    "parse_subitem_skeleton(list(reversed('l(e,l(H,T))')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the implementation of `parse_subitem()` and `parse_subitem_sequence()`.\n",
    "\n",
    "Both `parse_subitem()` and `parse_subitem_sequence()` are defined as class methods, with a first parameter, `_class`, whose value will be provided by the class from which the method is called. So in the case of `parse_subitem()`, the first character of the string to parse can be properly valided (it should be a lowercase letter when parsing an atom; it should be a letter that can be either lowercase or uppercase, or an underscore, when parsing a term), and eventually, the right type of object can be created. At this stage of the discussion, `parse_subitem()` seems to be useful to parse either atoms or terms, whereas `parse_subitem_sequence()` seems to be useful only to parse sequences of terms, and indeed the calls to `parse_subitem_sequence()` by `parse_subitem()` will actually be calls to `Term.parse_subitem_sequence()`. But to parse the bodies of the rules of a logic program, we will have to parse sequence of atoms; `parse_subitem_sequence()` will be perfectly suitable for the task, with the `_class` parameter of `parse_subitem_sequence()` set to `Atom`.\n",
    "\n",
    "It was tacitly assumed that `parse_subitem_skeleton()` and `parse_subitem_sequence_skeleton()` would be used only to parse a syntactically correct expression; `parse_subitem()` and `parse_subitem_sequence()` make no such assumption, so also check for syntactic correctness, and return `None` whenever they find out that there are characters that cannot be for a syntactically correct expression.\n",
    "\n",
    "* Before it calls `parse_word()`, `parse_subitem()` checks that there is indeed at least one character to parse, and that the first character to parse is as described in the previous item; otherwise, `parse_subitem()` returns `None`. The check is achieved thanks to one of two static methods, both with the name `starts_well()`, one being part of the `Term` class, the other one being part of the `Atom` class. The value of the `_class` parameter of `parse_subitem()` allows one to call the appropriate method.\n",
    "* In case `parse_subitem()` does not process a nullary predicate or function symbol or a variable, because it finds an opening parenthesis and calls `parse_subitem_sequence()`, and provided that the latter successfully parses a sequence of expressions and does not return `None` (otherwise, `parse_subitem()` should itself return `None`), it needs to finally check that there are some characters left, with as first character to parse, a closing parenthesis.\n",
    "* As for `parse_subitem_sequence()`, provided that all calls to `parse_subitem()` successfully parse an expression and do not return `None` (otherwise, `parse_subitem_sequence()` should itself return `None`), it has to check whether there is at least one character left. If that character is a comma, then the character can be popped and further expressions still have to be parsed in the sequence being currently dealt with. Otherwise, `parse_subitem_sequence()` returns the sequence of expressions it has successfully parsed and leaves it to `parse_subitem()` to act appropriately, whether or not there is at least one character left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expression(Expression):\n",
    "    @classmethod\n",
    "    def parse_subitem(_class, characters):\n",
    "        if not characters or not _class.starts_well(characters[-1]):\n",
    "            return\n",
    "        symbol = Expression.parse_word(characters)\n",
    "        if not characters or characters[-1] != '(':\n",
    "            return _class(symbol)\n",
    "        characters.pop()\n",
    "        subitems = Term.parse_subitem_sequence(characters)\n",
    "        if not subitems or not characters or characters.pop() != ')':\n",
    "            return\n",
    "        return _class(symbol, subitems)\n",
    "\n",
    "    @classmethod\n",
    "    def parse_subitem_sequence(_class, characters):\n",
    "        items = []\n",
    "        while True:\n",
    "            item = _class.parse_subitem(characters)\n",
    "            if not item:\n",
    "                return\n",
    "            items.append(item)\n",
    "            if not characters or characters[-1] != ',':\n",
    "                return items\n",
    "            characters.pop()\n",
    "\n",
    "\n",
    "class Term(Term, Expression):\n",
    "    @staticmethod\n",
    "    def starts_well(c):\n",
    "        return c.isidentifier()\n",
    "\n",
    "\n",
    "class Atom(Atom, Expression):\n",
    "    @staticmethod\n",
    "    def starts_well(c):\n",
    "        return c.islower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = Term.parse_subitem(list(reversed('bob')))\n",
    "print(type(expression), expression)\n",
    "\n",
    "expression = Term.parse_subitem(list(reversed('l(e,l(H,T))')))\n",
    "print(type(expression), expression)\n",
    "\n",
    "expression = Atom.parse_subitem(list(reversed('father(bob,sandra)')))\n",
    "print(type(expression), expression)\n",
    "\n",
    "expression = Atom.parse_subitem(list(reversed('join(l(H,T),X,l(H,Y))')))\n",
    "print(type(expression), expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extend the `Expression`, `Term` and `Atom` classes with three functions, `parse_item()`, `parse_term()` and `parse_atom()`, respectively. Whereas `parse_term()` and `parse_atom()` are defined as static methods, `parse_item()` is defined as a class method. Calling `parse_term()` and `parse_atom()` as `Term.parse_term()` and `Atom.parse_atom()`, respectively, lets `parse_item()` be aware of the type of object it is requested to create, as its first argument. Essentially, `parse_item()` creates a list of nonspace characters from the string to parse, reversing the order of its characters, and then calls `parse_subitem()`, either as `Term.parse_subitem()` or as `Atom.parse_subitem()` depending on how `parse_item()` has been called.\n",
    "\n",
    "We provide `parse_item()` with a third parameter, namely, `parse_subitem`, with a default value of `True`. This is because we will later have to parse rules, so rule bodies, which are sequences of atoms. As already mentioned, in order to parse a rule body, a call to `parse_item_sequence()` (passing `Atom` as value for its `_class` argument) will do the job; setting `parse_subitem` to `False` will let `parse_item()` know that it needs to call `parse_item_sequence()` rather than `parse_subitem()`.\n",
    "\n",
    "Finally, `parse_term()` and `parse_atom()` take advantage via `parse_item()` of the syntactic checks performed by `parse_subitem()` and `parse_item_sequence()`, as these functions return `None` when one of the checks they perform fails. Even when `parse_subitem()` and `parse_item_sequence()` do not return `None`, `parse_term()` and `parse_atom()` can fail to return a `Term` or an `Atom` object, respectively, when a last round of syntactic checks by `Term`'s or `Atom`'s `__init__()` method results in a `TermError` or an `AtomError` error being raised, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expression(Expression):\n",
    "    @classmethod\n",
    "    def parse_item(_class, expression, parse_subitem=True):\n",
    "        characters = list(reversed(expression.replace(' ', '')))\n",
    "        item = _class.parse_subitem(characters)\\\n",
    "                  if parse_subitem\\\n",
    "                  else Atom.parse_subitem_sequence(characters)\n",
    "        if not item or characters:\n",
    "            return\n",
    "        return item\n",
    "\n",
    "\n",
    "class Term(Term, Expression):\n",
    "    @staticmethod\n",
    "    def parse_term(expression):\n",
    "        term = Term.parse_item(expression)\n",
    "        if not term:\n",
    "            raise Term.TermError(f'{expression} is syntactically incorrect')\n",
    "        return term\n",
    "\n",
    "\n",
    "class Atom(Atom, Expression):\n",
    "    @staticmethod\n",
    "    def parse_atom(expression):\n",
    "        atom = Atom.parse_item(expression)\n",
    "        if not atom:\n",
    "            raise Atom.AtomError(f'{expression} is syntactically incorrect')\n",
    "        return atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = Term.parse_term('X')\n",
    "print(type(term), term)\n",
    "\n",
    "term = Term.parse_term('bob')\n",
    "print(type(term), term)\n",
    "\n",
    "term = Term.parse_term('l(e, l(H, T))')\n",
    "print(type(term), term)\n",
    "\n",
    "atom = Atom.parse_atom('father(bob, sandra)')\n",
    "print(type(atom), atom)\n",
    "\n",
    "atom = Atom.parse_atom('join(l(H, T), X, l(H, Y))')\n",
    "print(type(atom), atom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Term.parse_term('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Term.parse_term('father(bob, sandra))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Term.parse_term('father(bob, , sandra)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Term.parse_term('father(bob, father(sandra, john, mary))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atom.parse_atom('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atom.parse_atom('l(e, l(H, T))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing how to parse terms and atoms and create `Term` and `Atom` objects, respectively, we can now define a number of functions to operate on `Expression` objects as needed by a Prolog interpreter. It is necessary to be able to collect all variables that occur in an expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expression(Expression):\n",
    "    def variables(self):\n",
    "        variables = {self.root} if self.is_variable() else set()\n",
    "        variables.update(*(child.variables() for child in self.children))\n",
    "        return variables\n",
    "\n",
    "\n",
    "class Term(Term, Expression):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Atom(Atom, Expression):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Term.parse_term('x').variables()\n",
    "Term.parse_term('X').variables()\n",
    "Term.parse_term('f(X, a, X)').variables()\n",
    "Term.parse_term('f(X_0, Y, X_0)').variables()\n",
    "Term.parse_term('f(c, f(X, f(a, Z, b), '\n",
    "                'f(f(X, Z, U), a, T)), f(a, U, a))'\n",
    "               ).variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prolog considers underscores within a rule as independent variables. For instance, the fact $\\mathit{loves}(\\_,\\_).$ is meant to express that everyone loves everyone (including oneself), not only that everyone loves oneself: the two occurrences of $\\_$ denote arbitrary, independant individuals, and $\\mathit{loves}(\\_,\\_)$ has the same intended meaning as $\\mathit{loves}(\\_0,\\_1)$. A Prolog interpreter needs to treat all occurrences of a given variable in a rule as denotations of the same individual (as a consequence, a Prolog interpreter needs to make sure that whenever an occurrence of a variable in a rule is replaced by a term, then all other occurrences of the variable in the rule are replaced by the term). To that aim, we define in `Expression` a recursive method, `individualise_underscores()`, meant to let in an expression each occurrence of an underscore, used as a full name for a variable, be followed by a unique natural number. We first explain how the method operates thanks to a tracing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_individualise_underscores(expression, variables, index, depth):\n",
    "    print('  ' * depth, f'Received index is {index}, processing', expression)\n",
    "    if expression.root == '_':\n",
    "        while True:\n",
    "            index += 1\n",
    "            next_underscore = '_' + str(index)\n",
    "            if next_underscore not in variables:\n",
    "                expression.root = next_underscore\n",
    "                print('  ' * depth, f'_ changed to {expression}, returned '\n",
    "                      'index is', index\n",
    "                     )\n",
    "                return index\n",
    "    if not expression.children:\n",
    "        print('  ' * depth, 'Returned index is', index)\n",
    "        return index\n",
    "    for child in expression.children:\n",
    "        index = trace_individualise_underscores(child, variables, index,\n",
    "                                                depth + 1\n",
    "                                               )\n",
    "    print('  ' * depth, 'Returned index is', index)\n",
    "    return index\n",
    "    \n",
    "atom = Atom.parse_atom('p(g(h(a, _), X), _2, h(a, _), _)')\n",
    "variables = atom.variables()\n",
    "print('Variables in expression are:', variables, end='\\n\\n')\n",
    "trace_individualise_underscores(atom, variables, -1, 0)\n",
    "print('expression now is:', atom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of `individualise_underscores()` in the following cell is a straightforward adaptation of `trace_individualise_underscores()`. When dealing with a fact, `individualise_underscores()` can be called on the `Atom` object that captures the fact, and the default arguments are appropriate. When dealing with a more general rule, `individualise_underscores()` can be called on the rule's head, but the argument `variables` should be given as value the set $S$ of variables that occur in the whole rule, not just in the rule's head; that call would return an integer $i_1$. Then `individualise_underscores()` can be called on the first atom in the rule's body, with `variables` still set to $S$, but with the argument `index` given the value $i_1$; that call would return an integer $i_2$. Then `individualise_underscores()` can be called on the second atom in the rule's body, if any, with `variables` still set to $S$, but with the argument `index` given the value $i_2$... That is a way to give each underscore that occurs in the rule a unique name, not occurring anywhere in the rule. That is not something to see in action yet as for now, we are only dealing with terms and atoms, not rules and logic programs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expression(Expression):\n",
    "    def individualise_underscores(self, variables=None, index=-1):\n",
    "        if variables is None:\n",
    "            variables = self.variables()\n",
    "        if self.root == '_':\n",
    "            while True:\n",
    "                index += 1\n",
    "                next_underscore = '_' + str(index)\n",
    "                if next_underscore not in variables:\n",
    "                    self.root = next_underscore\n",
    "                    return index\n",
    "        if not self.children:\n",
    "            return index\n",
    "        for child in self.children:\n",
    "            index = child.individualise_underscores(variables, index)\n",
    "        return index\n",
    "\n",
    "\n",
    "class Term(Term, Expression):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Atom(Atom, Expression):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom = Atom.parse_atom('p(g(h(a, _), X), _2, h(a, _), _)')\n",
    "atom.individualise_underscores()\n",
    "print(atom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Prolog interpreter needs to be able to substitute in an expression $E$ all occurrences of some of the variables that occur in $E$ by terms; sometimes, the terms will simply be computed fresh variables, for a particular kind of substitution referred to as a _renaming of variables in $E$_. We extend `Expression` with a static method, `fresh_variables()`, meant to take two arguments, `variables` and `reserved_variables`, both expected to be sets of variables, and return a dictionary $D$ whose keys are the members of both `variables` and `reserved_variables`, and whose values are pairwise distinct variables, different to those in both sets. The intention is that given an expression $E$, `variables` will denote the set of variables that occur in $E$; any such variable $v$ that happens to belong to `reserved_variables` can then be replaced by $D[v]$ in $E$, resulting in an expression where fresh variables have replaced those in both `variables` and `reserved_variables`. We let the name of a variable that belongs to both `variables` and `reserved_variables` be followed by an underscore and the smallest possible natural number for the mapped to fresh variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expression(Expression):\n",
    "    @staticmethod\n",
    "    def fresh_variables(variables, reserved_variables):\n",
    "        substitutions = {}\n",
    "        # Any variable Var that occurs in both variables and\n",
    "        # reserved_variables will be renamed to Var_i where i is the\n",
    "        # least natural number that makes Var_i a new variable (that is,\n",
    "        # occurring neither in variables nor in reserved_variables nor\n",
    "        # in the set of variables that have been created so far, if\n",
    "        # any).\n",
    "        for variable in variables & reserved_variables:\n",
    "            i = 0\n",
    "            while ''.join((variable, '_', str(i))) in variables\\\n",
    "                                                      | reserved_variables:\n",
    "                i += 1\n",
    "            substitutions[variable] = ''.join((variable, '_', str(i)))\n",
    "        return substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Expression.fresh_variables({'a'}, set())\n",
    "Expression.fresh_variables({'Y'}, {'X'})\n",
    "Expression.fresh_variables({'X'}, {'X'})\n",
    "Expression.fresh_variables({'Y', 'Z'}, {'X', 'Y'})\n",
    "Expression.fresh_variables({'U', 'Y', 'Z'}, {'X', 'Y', 'Z'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the Prolog interpreter needs to rename variables in an expression $E$, it  actually always has to leave $E$ untouched and perform the renaming on a copy of $E$. The `deepcopy` function from the `copy` module offers a good solution to cloning an `Expression` object. Compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [0]\n",
    "# Alternatively, use the copy method of the List class:\n",
    "# L_copy = L.copy()\n",
    "L_copy = copy(L)\n",
    "L_copy[0] = 1\n",
    "L_copy, L\n",
    "\n",
    "L = [[0]]\n",
    "# Alternatively, use the copy method of the List class:\n",
    "# L_copy = L.copy()\n",
    "L_copy = copy(L)\n",
    "L_copy[0][0] = 1\n",
    "L_copy, L\n",
    "\n",
    "L = [[0]]\n",
    "L_deepcopy = deepcopy(L)\n",
    "L_deepcopy[0][0] = 1\n",
    "L_deepcopy, L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extend `Expression` with a method, `rename_variables()`, that recursively renames variables in a copy of an expression, the renaming taking the form of a dictionary mapping variables to replace to replacing variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expression(Expression):\n",
    "    def rename_variables(self, substitution):\n",
    "        return deepcopy(self)._rename_variables(substitution)\n",
    "\n",
    "    def _rename_variables(self, substitution):\n",
    "        if self.is_variable():\n",
    "            if self.root in substitution:\n",
    "                self.root = substitution[self.root]\n",
    "        else:\n",
    "            for child in self.children:\n",
    "                child._rename_variables(substitution)\n",
    "        return self\n",
    "\n",
    "\n",
    "class Term(Term, Expression):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Atom(Atom, Expression):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom = Atom.parse_atom('join(l(H, T),X, l(H, Y))')\n",
    "print(atom.rename_variables({'X': 'A', 'Y': 'B', 'Z': 'C'}))\n",
    "print(atom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More general substitutions of variables by terms in an expression $E$ will have to be performed sometimes in $E$ itself, sometimes in a copy of $E$. We extend `Expression` with two methods, `substitute()` and `substitute_in_copy()`, for both kinds of substitutions, the latter just calling the former on a copy of the object it applies the method to. When a term $t$ replaces a variable $v$ in $E$, $t$ might itself contain variables that belong to the domain of the substitution. In that case, we apply the substitution again, many times if needed. If the substitution requested to replace a variable by itself, or requested to replace a variable $v_1$ by a variable $v_2$ and the other way around, the procedure would loop forever. The kind of substitution that will be used in practice will not make this possible: after a finite number of applications of the substitution, the resulting expression will contain no occurrence of a variable in the domain of the substitution. Note that the assignment in the body of `substitute()` cannot be replaced by `self = substitution[self.root]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expression(Expression):\n",
    "    def substitute_in_copy(self, substitution):\n",
    "        return deepcopy(self).substitute(substitution)\n",
    "\n",
    "    def substitute(self, substitution):\n",
    "        if self.is_variable():\n",
    "            if self.root in substitution:\n",
    "                self.root, self.children = substitution[self.root].root,\\\n",
    "                                           substitution[self.root].children\n",
    "                self.substitute(substitution)\n",
    "        else:\n",
    "            for child in self.children:\n",
    "                child.substitute(substitution)\n",
    "        return self\n",
    "\n",
    "\n",
    "class Term(Term, Expression):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Atom(Atom, Expression):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = Term.parse_term('f(a, X, g(Y, b), h(h(h(Z))))')\n",
    "print(term.substitute({'X': Term.parse_term('X_0'), 'Z': Term.parse_term('Z_0')\n",
    "                      }\n",
    "                     )\n",
    "     )\n",
    "\n",
    "term = Term.parse_term('h(h(f(U, Y, g(Z, Z))))')\n",
    "print(term.substitute({'Z': Term.parse_term('V')}))\n",
    "\n",
    "term = Term.parse_term('f(a, X, g(Y, b), h(h(h(Z))))')\n",
    "print(term.substitute({'X_0' : Term.parse_term('h(Z_0)'),\n",
    "                       'X': Term.parse_term('X_0'), 'Z_0': Term.parse_term('c')\n",
    "                      }\n",
    "                     )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the heart of Prolog lies the _unification algorithm_. It computes a most general unifier (_mgu_) for two expressions $E_1$ and $E_2$, that is, a substitution $\\theta$ such that:\n",
    "\n",
    "* applying $\\theta$ to $E_1$ and $E_2$ results in the same expression;\n",
    "* for any substitution $\\psi$ that applied to $E_1$ and $E_2$, results in the same expression, there exists a substitution $\\nu$ such that applying $\\psi$ to $E_1$ and $E_2$ is the same as applying $\\theta$ to $E_1$ and $E_2$, and then $\\nu$ to the resulting expressions.\n",
    "\n",
    "For instance, if $E_1$ is $f(X_1, h(X_1), X_2)$ and $E_2$ is $f(g(X_3), X_4, X_3)$, then the substitution that maps $X_1$ to $g(X_3)$, $X_2$ to $X_3$ and $X_4$ to $h(g(X_3))$ is an mgu for $E_1$ and $E_2$; when applied to $E_1$ and $E_2$, it results in the expression $f(g(X_3), h(g(X_3)), X_3)$. If $a$ is a constant, then the substitution that maps $X_1$ to $g(a)$, $X_2$ and $X_3$ to $a$ and $X_4$ to $h(g(a))$ results in the same expression when applied to $E_1$ and $E_2$, namely, $f(g(a), h(g(a)), a)$; but it suffices to apply the substitution that maps $X_3$ to $a$ to get $f(g(a), h(g(a)), a)$ from $f(g(X_3), h(g(X_3)), X_3)$.\n",
    "\n",
    "So a most general unifier for two expressions $E_1$ and $E_2$ is a substitution $\\theta$ that specialises $E_1$ and $E_2$ to the same expression in the most general way: any other substitution that specialises $E_1$ and $E_2$ to the same expression can be obtained by instantiating $\\theta$. A most general unifier is unique up to a renaming of variables.\n",
    "\n",
    "The following tracing function, `trace_unify_identities()`, is meant to explain and illustrate the unification algorithm. It takes as argument a list of pairs of expressions. To compute an mgu for two expressions $E_1$ and $E_2$, `trace_unify_identities()` is called with $[(E_1,E_2)]$ provided as argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_unify_identities(identities):\n",
    "    mgu = {}\n",
    "    while identities:\n",
    "        print('Identities left to process: ', end='')\n",
    "        print(', '.join(f'{identity[0]} = {identity[1]}'\n",
    "                            for identity in identities\n",
    "                       )\n",
    "             )\n",
    "        expression_1, expression_2 = identities.pop()\n",
    "        print('    Dealing with:', expression_1, '=', expression_2)\n",
    "        if expression_1.root == expression_2.root:\n",
    "            for (expr_1, expr_2) in zip(expression_1.children,\n",
    "                                        expression_2.children\n",
    "                                       ):\n",
    "                print('    Adding:', expr_1, '=', expr_2)\n",
    "                identities.append([expr_1, expr_2])\n",
    "        elif expression_1.is_variable():\n",
    "            # Occurrence check (omitted in most Prolog implementations)\n",
    "            if expression_1.root in expression_2.variables():\n",
    "                print(f'    {expression_1.root} occurs in {expression_2},',\n",
    "                      'giving up!'\n",
    "                     )\n",
    "                return\n",
    "            print('    Extending mgu with:', expression_1.root, '->',\n",
    "                  expression_2\n",
    "                 )\n",
    "            mgu[expression_1.root] = expression_2\n",
    "            for identity in identities:\n",
    "                print('    Changing (or not)', identity[0], '=', identity[1],\n",
    "                      'to ', end=''\n",
    "                     )\n",
    "                for i in range(2):\n",
    "                    identity[i] = identity[i].substitute_in_copy(\n",
    "                                            {expression_1.root: expression_2}\n",
    "                                                                )\n",
    "                print(identity[0], '=', identity[1])\n",
    "        elif expression_2.is_variable():\n",
    "            print('    Adding', expression_2, '=', expression_1)\n",
    "            identities.append([expression_2, expression_1])\n",
    "        else:\n",
    "            print('    Equality cannot be satisfied, giving up!')\n",
    "            return\n",
    "        print()\n",
    "    print('Mgu:')\n",
    "    print('\\n'.join(f'    {var} -> {mgu[var]}' for var in mgu))\n",
    "    return mgu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_1 = Term.parse_term('X')\n",
    "term_2 = Term.parse_term('X')\n",
    "mgu = trace_unify_identities([(term_1, term_2)])\n",
    "\n",
    "if mgu is not None:\n",
    "    print('\\nExpressions after application of mgu:')\n",
    "    print('   ', term_1.substitute(mgu))\n",
    "    print('   ', term_2.substitute(mgu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_1 = Term.parse_term('X')\n",
    "term_2 = Term.parse_term('a')\n",
    "mgu = trace_unify_identities([(term_1, term_2)])\n",
    "\n",
    "if mgu is not None:\n",
    "    print('\\nExpressions after application of mgu:')\n",
    "    print('   ', term_1.substitute(mgu))\n",
    "    print('   ', term_2.substitute(mgu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_1 = Term.parse_term('X')\n",
    "term_2 = Term.parse_term('Y')\n",
    "mgu = trace_unify_identities([(term_1, term_2)])\n",
    "\n",
    "if mgu is not None:\n",
    "    print('\\nExpressions after application of mgu:')\n",
    "    print('   ', term_1.substitute(mgu))\n",
    "    print('   ', term_2.substitute(mgu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_1 = Term.parse_term('f(X, Y)')\n",
    "term_2 = Term.parse_term('f(Y, X)')\n",
    "mgu = trace_unify_identities([(term_1, term_2)])\n",
    "\n",
    "if mgu is not None:\n",
    "    print('\\nExpressions after application of mgu:')\n",
    "    print('   ', term_1.substitute(mgu))\n",
    "    print('   ', term_2.substitute(mgu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_1 = Term.parse_term('f(X1, h(X1), X2)')\n",
    "term_2 = Term.parse_term('f(g(X3), X4, X3)')\n",
    "mgu = trace_unify_identities([(term_1, term_2)])\n",
    "\n",
    "if mgu is not None:\n",
    "    print('\\nExpressions after application of mgu:')\n",
    "    print('   ', term_1.substitute(mgu))\n",
    "    print('   ', term_2.substitute(mgu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_1 = Term.parse_term('f(X1 ,g(X2, X3), X2, b)')\n",
    "term_2 = Term.parse_term('f(g(h(a, X5), X2), X1, h(a, X4), X4)')\n",
    "mgu = trace_unify_identities([(term_1, term_2)])\n",
    "\n",
    "if mgu is not None:\n",
    "    print('\\nExpressions after application of mgu:')\n",
    "    print('   ', term_1.substitute(mgu))\n",
    "    print('   ', term_2.substitute(mgu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_1 = Term.parse_term('f(X, a)')\n",
    "term_2 = Term.parse_term('f(b, X)')\n",
    "mgu = trace_unify_identities([(term_1, term_2)])\n",
    "\n",
    "if mgu is not None:\n",
    "    print('\\nExpressions after application of mgu:')\n",
    "    print('   ', term_1.substitute(mgu))\n",
    "    print('   ', term_2.substitute(mgu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_1 = Term.parse_term('f(X, Y, U)')\n",
    "term_2 = Term.parse_term('f(Y, U, g(X))')\n",
    "mgu = trace_unify_identities([(term_1, term_2)])\n",
    "\n",
    "if mgu is not None:\n",
    "    print('\\nExpressions after application of mgu:')\n",
    "    print('   ', term_1.substitute(mgu))\n",
    "    print('   ', term_2.substitute(mgu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the unification algorithm in `Expression` should now be clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expression(Expression):\n",
    "    @staticmethod\n",
    "    def unify_identities(identities):\n",
    "        mgu = {}\n",
    "        while identities:\n",
    "            expression_1, expression_2 = identities.pop()\n",
    "            if expression_1.root == expression_2.root:\n",
    "                identities.extend([expr_1, expr_2] for (expr_1, expr_2) in\n",
    "                                                     zip(expression_1.children,\n",
    "                                                         expression_2.children\n",
    "                                                        )\n",
    "                                 )\n",
    "            elif expression_1.is_variable():\n",
    "                # Occurrence check (omitted in most Prolog\n",
    "                # implementations)\n",
    "                if expression_1.root in expression_2.variables():\n",
    "                    return\n",
    "                mgu[expression_1.root] = expression_2\n",
    "                for identity in identities:\n",
    "                    for i in range(2):\n",
    "                        identity[i] = identity[i].substitute_in_copy(\n",
    "                                              {expression_1.root: expression_2}\n",
    "                                                                    )\n",
    "            elif expression_2.is_variable():\n",
    "                identities.append([expression_2, expression_1])\n",
    "            else:\n",
    "                return\n",
    "        return mgu\n",
    "            \n",
    "    def unify(self, expression):\n",
    "        return Expression.unify_identities([[self, expression]])\n",
    "\n",
    "\n",
    "class Term(Term, Expression):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Atom(Atom, Expression):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = Term.parse_term('X')\n",
    "mgu = term.unify(Term.parse_term('X'))\n",
    "{var: str(mgu[var]) for var in mgu}\n",
    "\n",
    "term = Term.parse_term('X')\n",
    "mgu = term.unify(Term.parse_term('a'))\n",
    "{var: str(mgu[var]) for var in mgu}\n",
    "\n",
    "term = Term.parse_term('X')\n",
    "mgu = term.unify(Term.parse_term('Y'))\n",
    "{var: str(mgu[var]) for var in mgu}\n",
    "\n",
    "term = Term.parse_term('f(X, Y)')\n",
    "mgu = term.unify(Term.parse_term('f(Y, X)'))\n",
    "{var: str(mgu[var]) for var in mgu}\n",
    "\n",
    "term = Term.parse_term('f(X1, h(X1), X2)')\n",
    "mgu = term.unify(Term.parse_term('f(g(X3), X4, X3)'))\n",
    "{var: str(mgu[var]) for var in mgu}\n",
    "\n",
    "term = Term.parse_term('f(X1 ,g(X2, X3), X2, b)')\n",
    "mgu = term.unify(Term.parse_term('f(g(h(a, X5), X2), X1, h(a, X4), X4)'))\n",
    "{var: str(mgu[var]) for var in mgu}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the code we need to build and operate on terms and atoms. We can now further compose:\n",
    "\n",
    "* conjunctions of atoms as rule bodies;\n",
    "* rule heads (atoms) and rule bodies as rules;\n",
    "* sequences of rules as logic programs.\n",
    "\n",
    "We define a new class for each: `Conjunction`, `Rule`, and `LogicProgram`.\n",
    "\n",
    "A `Conjunction` object is intended to be a list of `Atom` objects. This is achieved by letting `Conjunction` inherit from `list`, together with a static method, `parse_conjunction()`, whose implementation is similar to `Term`'s  `parse_term()` and `Atom`'s `parse_atom()`static methods, respectively: `parse_conjunction()` calls `Expression`'s `parse_item()` method, but with its keyword argument `parse_subitem` set to `False`, so that it then calls `parse_subitem_sequence()` rather than `parse_subitem()`, as previously discussed. Also, the implementation of `Conjunction`'s `__init__()` method is similar to the implementation of `Term`'s and `Atom`'s `__init__()` methods:\n",
    "\n",
    "* It collects all function symbols and all predicate symbols that occur in at least one atom in the conjunction, in the form of two dictionaries, with symbols as keys and symbols' arities as values.\n",
    "* A `ConjunctionError` error is raised by `parse_conjunction()` in case the call to `parse_item()` fails to return a list of `Atom` objects, or during a last round of syntactic checks by `Conjunction`'s `__init__()` method, to make sure that:\n",
    "    * no predicate symbol and no function symbol is used with different arities in different atoms;\n",
    "    * no symbol is used as a predicate symbol in an atom and as a function symbol in another atom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conjunction(list, Expression):\n",
    "    class ConjunctionError(Exception):\n",
    "        pass\n",
    "\n",
    "    def __init__(self, conjuncts=[]):\n",
    "        super().__init__(conjuncts)\n",
    "        self.predicate_symbols = {}\n",
    "        self.function_symbols = {}\n",
    "        if not consistently_add_to(self.predicate_symbols, \n",
    "                                   *((atom.root, len(atom.children))\n",
    "                                        for atom in self\n",
    "                                    )\n",
    "                                  ):\n",
    "            raise Conjunction.ConjunctionError('Predicate symbol used with '\n",
    "                                               f'different arities in {self}'\n",
    "                                              )\n",
    "        for atom in self:\n",
    "            if not consistently_add_to(self.function_symbols,\n",
    "                                       *atom.function_symbols.items()\n",
    "                                      ):\n",
    "                raise Conjunction.ConjunctionError('Function symbol used with '\n",
    "                                                   'different arities in '\n",
    "                                                   f'{self}'\n",
    "                                                  )\n",
    "        if self.predicate_symbols.keys() & self.function_symbols.keys():\n",
    "            raise Conjunction.ConjunctionError('Predicate symbol also '\n",
    "                                               f'function symbol in {self}'\n",
    "                                              )\n",
    "\n",
    "    def __str__(self):\n",
    "        return ', '.join(str(atom) for atom in self)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_conjunction(expression):\n",
    "        if expression.isspace():\n",
    "            return Conjunction()\n",
    "        conjunction = Expression.parse_item(expression, parse_subitem=False)\n",
    "        if not conjunction:\n",
    "            raise Conjunction.ConjunctionError(f'{expression} is '\n",
    "                                               'syntactically incorrect'\n",
    "                                              )\n",
    "        return Conjunction(conjunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunction = Conjunction.parse_conjunction('father')\n",
    "print(conjunction)\n",
    "conjunction.predicate_symbols, conjunction.function_symbols\n",
    "\n",
    "conjunction =\\\n",
    "          Conjunction.parse_conjunction('male(X), parent(Z, X), parent(Z, Y)')\n",
    "print(conjunction)\n",
    "conjunction.predicate_symbols, conjunction.function_symbols\n",
    "\n",
    "conjunction = Conjunction.parse_conjunction('reduce(X, add(mult(N, x), M1)), '\n",
    "                                            'reduce(Y, add(mult(o, x), M2)), '\n",
    "                                            'plus(M1, M2, M)'\n",
    "                                           )\n",
    "print(conjunction)\n",
    "conjunction.predicate_symbols, conjunction.function_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conjunction.parse_conjunction('plus(X, Y, U), plus(times(U, Y, Z)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conjunction.parse_conjunction('male(X), parent(Z, X), parent(male(Z), Y)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we implement the `Rule` class. Besides the `function_symbols` and `predicate_symbols` attributes, objects of type `Rule` have a `head` attribute, meant to denote an `Atom` object, a `body` attribute, meant to denote a `Conjunction` object, and a `variables` attribute, meant to denote the set of variables occurring in the atoms that make up a rule. The `Rule` class has a `parse_rule()` static method that makes sure a rule ends in a full stop and either consists of a single fact, or has a head and a body separated by `:-`; it then relies on the `Atom.parse_atoms()` and `Conjunction.parse_conjunction()` static methods to parse head and body and return `Atom` and `Conjunction` objects, respectively. Besides all syntactic checks performed by those two functions, `Rule`'s `__init__()` method makes sure that:\n",
    "\n",
    "* the predicate symbol in the head is not used as a predicate symbol with a different arity in the body;\n",
    "* no function symbol in the head is used as a function symbol with a different arity in the body;\n",
    "* no symbol is used as a predicate symbol in the head and as a function symbol in the body, or the other way around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class Rule:\n",
    "    class RuleError(Exception):\n",
    "        pass\n",
    "\n",
    "    def __init__(self, head, body=Conjunction()):\n",
    "        self.head = head\n",
    "        self.body = body\n",
    "        self.variables =  self.head.variables()\n",
    "        self.variables.update(*(atom.variables() for atom in self.body))\n",
    "        if not self.body:\n",
    "            return\n",
    "        if not consistently_add_to({self.head.root: len(self.head.children)}, \n",
    "                                   *self.body.predicate_symbols.items()\n",
    "                                  ):\n",
    "            raise Rule.RuleError(\"Head's predicate symbol used with \"\n",
    "                                 f'different arities in {self}'\n",
    "                                )\n",
    "        if not consistently_add_to(self.head.function_symbols, \n",
    "                                   *self.body.function_symbols.items()\n",
    "                                  ):\n",
    "            raise Rule.RuleError('Function symbol used with different '\n",
    "                                 f'arities in head and body of {self}'\n",
    "                                )\n",
    "        if self.head.root in self.body.function_symbols:\n",
    "            raise Rule.RuleError('Predicate symbol in head also '\n",
    "                                 f'function symbol in body of {self}'\n",
    "                                )\n",
    "        if self.head.function_symbols.keys()\\\n",
    "           & self.body.predicate_symbols.keys():\n",
    "            raise Rule.RuleError('Function symbol in head also '\n",
    "                                 f'predicate symbol in body of {self}'\n",
    "                                )\n",
    "\n",
    "    def __str__(self):\n",
    "        if not self.body:\n",
    "            return str(self.head) + '.'\n",
    "        return ' :- '.join((str(self.head),\n",
    "                            ', '.join(str(atom) for atom in self.body)\n",
    "                           )\n",
    "                          ) + '.'\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_rule(expression):\n",
    "        if expression[-1] != '.':\n",
    "            raise Rule.RuleError(f'{expression} does not end in a full stop')\n",
    "        rule = expression[: -1].split(':-')\n",
    "        if len(rule) < 1 or len(rule) > 2 or\\\n",
    "           len(rule) == 2 and rule[1].isspace():\n",
    "            raise Rule.RuleError(f'{expression} is syntactically invalid')\n",
    "        head = Atom.parse_atom(rule[0])\n",
    "        if len(rule) == 1:\n",
    "            return Rule(head)\n",
    "        return Rule(head, Conjunction.parse_conjunction(rule[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = Rule.parse_rule('female(alice).')\n",
    "print(rule)\n",
    "rule.variables\n",
    "\n",
    "rule = Rule.parse_rule('sisterof(X, Y)  :-  parents(X, M, F), female(X), '\n",
    "                       'parents(Y, M, F).'\n",
    "                      )\n",
    "print(rule)\n",
    "rule.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rule.parse_rule('female(alice)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rule.parse_rule(' :- female(alice).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rule.parse_rule(' female(alice) :- .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rule.parse_rule('sisterof(X, Y)  :-  parents(X, M, F), sisterof(X),'\n",
    "                ' parents(Y, M, F).'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rule.parse_rule('times(s(X), Y, Z) :- plus(X, Y, U), minus(times(U, Y, Z)).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we implement that part of the `LogicProgram` class that creates a logic program object from the contents of a file, with three attributes: `program`, meant to denote a list of `Rule` objects, and `predicate_symbols` and `function_symbols`, meant to denote the sets of predicate and function symbols, respectively, occurring in the rules that make up the logic program. `LogicProgram`'s `__init__()` method makes sure that:\n",
    "\n",
    "* no predicate symbol or function symbol is used with different arities in different rules;\n",
    "* no symbol is used both as a predicate symbol and as a function symbol in different rules.\n",
    "\n",
    "Prolog comments start with `%`; lines in the file whose first nonspace symbol is `%`, as well as blank lines, are ignored.\n",
    "\n",
    "The `individualise_underscores()` method of the `Expression` class is used to, for each rule, replace every occurrence of `_` in the rule as a new, unique variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicProgram:\n",
    "    class LogicProgramError(Exception): \n",
    "        pass\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.program = []\n",
    "        self.predicate_symbols = {}\n",
    "        self.function_symbols = {}\n",
    "        rule_nb = 0\n",
    "        with open(filename) as file:\n",
    "            for rule in file:\n",
    "                rule = rule.strip()\n",
    "                if not rule or rule.startswith('%'):\n",
    "                    continue\n",
    "                rule = Rule.parse_rule(rule)\n",
    "                rule_nb += 1\n",
    "                if not consistently_add_to(self.predicate_symbols,\n",
    "                                           (rule.head.root,\n",
    "                                            len(rule.head.children)\n",
    "                                           ),\n",
    "                                           *rule.body.predicate_symbols.items()\n",
    "                                          ):\n",
    "                    raise LogicProgram.LogicProgramError(\n",
    "                                'Predicate symbol used with different arities '\n",
    "                                f'in rule nb {rule_nb} and in previous rules'\n",
    "                                                        )\n",
    "                if not consistently_add_to(self.function_symbols,\n",
    "                                           *rule.head.function_symbols.items(),                                           \n",
    "                                           *rule.body.function_symbols.items()\n",
    "                                          ):\n",
    "                    raise LogicProgram.LogicProgramError(\n",
    "                                'Function symbol used with different arities '\n",
    "                                f'in rule nb {rule_nb} and in previous rules'\n",
    "                                                        )\n",
    "                if self.predicate_symbols.keys()\\\n",
    "                   & self.function_symbols.keys():\n",
    "                    raise LogicProgram.LogicProgramError(\n",
    "                          'Symbol used as both predicate and function symbols '\n",
    "                          f'in rule nb {rule_nb} and in previous rules'\n",
    "                                                        )\n",
    "                underscore_index =\\\n",
    "                        rule.head.individualise_underscores(rule.variables)\n",
    "                for atom in rule.body:\n",
    "                    underscore_index =\\\n",
    "                            atom.individualise_underscores(rule.variables,\n",
    "                                                           underscore_index\n",
    "                                                          )\n",
    "                self.program.append(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is now in place for the Prolog interpreter to solve queries, with an exploration of the search tree that defaults to depth-first, but that can be changed to breadth-first. The following tracing function, `trace_solve()`, is meant to explain and illustrate the workings of the interpreter. The second argument, `query`, is meant to be a string that represents a conjunction of atoms, possibly reduced to a single one, to be interpreted as a goal or an implicitly conjuncted sequence of goals. The only place where depth-first and breadth-first explorations differ is at the very end of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_solve(logic_program, query, depth_first=True):\n",
    "    query = Conjunction.parse_conjunction(query)\n",
    "    query_variables = {var for atom in query for var in atom.variables()}\n",
    "    # A list of pairs consisting of:\n",
    "    # - a list of goals to be solved, and\n",
    "    # - the substitution to apply to the variables that occur in the\n",
    "    #   query as determined by the unifications computed so far.\n",
    "    goals_solution_pairs =\\\n",
    "            deque([(deque(query), {var: Term(var) for var in query_variables})\n",
    "                  ]\n",
    "                 )\n",
    "    while goals_solution_pairs:\n",
    "        goals, solution = goals_solution_pairs.popleft()\n",
    "        print('\\nDealing with following goals and partial solution:')\n",
    "        print('   ', ', '.join(str(goal) for goal in goals), end='')\n",
    "        print('   ', ', '.join(f'{var} -> {solution[var]}'\n",
    "                                    for var in solution)\n",
    "             )\n",
    "        if not goals:\n",
    "            print('    No goal left, solution is complete')\n",
    "            yield {var: str(solution[var]) for var in solution}\n",
    "            continue\n",
    "        reserved_variables =\\\n",
    "          query_variables | {var for atom in goals for var in atom.variables()}\n",
    "        goal = goals.popleft()\n",
    "        next_goals_solution_pairs = deque()\n",
    "        for rule in logic_program.program:\n",
    "            variable_renaming = Expression.fresh_variables(rule.variables,\n",
    "                                                           reserved_variables\n",
    "                                                          )\n",
    "            head = rule.head.rename_variables(variable_renaming)\n",
    "            mgu = goal.unify(head)\n",
    "            if mgu is not None:\n",
    "                print('    First goal unified with head of rule:', rule)\n",
    "                print('      Renaming variables, head becomes:', head)\n",
    "                print('      Mgu:',\n",
    "                      ', '.join(f'{var} -> {mgu[var]}' for var in mgu)\n",
    "                     )\n",
    "                new_goals =\\\n",
    "                    deque(atom.rename_variables(variable_renaming)\\\n",
    "                              .substitute(mgu) for atom in rule.body\n",
    "                         )\n",
    "                new_goals.extend(goal.substitute_in_copy(mgu) for goal in goals\n",
    "                                )\n",
    "                if new_goals:\n",
    "                    print('      New goals to solve: ', end='')\n",
    "                    print(', '.join(str(goal) for goal in new_goals))\n",
    "                    print('      New partial solution:',\n",
    "                          ', '.join(f'{var} -> '\n",
    "                                    f'{solution[var].substitute_in_copy(mgu)}'\n",
    "                                            for var in solution\n",
    "                                   )\n",
    "                         )\n",
    "\n",
    "                next_goals_solution_pairs.append(\n",
    "                                   (new_goals,\n",
    "                                    {var: solution[var].substitute_in_copy(mgu)\n",
    "                                         for var in solution\n",
    "                                    }\n",
    "                                   )\n",
    "                                                )\n",
    "        if depth_first:\n",
    "            goals_solution_pairs.extendleft(reversed(next_goals_solution_pairs)\n",
    "                                           )\n",
    "        else:\n",
    "            goals_solution_pairs.extend(next_goals_solution_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat prolog_ex_1.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracing execution for a closed goal, so checking that the goal is a logical consequence of the logic program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_program = LogicProgram('prolog_ex_1.pl')\n",
    "for _ in trace_solve(logic_program, 'grandparent(john, jack)'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracing the depth-first search exploration for solutions to the goal `grandparent(john, X)` as illustrated with the first tree above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_program = LogicProgram('prolog_ex_1.pl')\n",
    "for _ in trace_solve(logic_program, 'grandparent(john, X)'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same but changing exploration to breadth-first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_program = LogicProgram('prolog_ex_1.pl')\n",
    "for _ in trace_solve(logic_program, 'grandparent(john, X)', False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat prolog_ex_2.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracing the depth-first search exploration for solutions to the goal `join(X, X, Y)` as illustrated with the third tree above yields the following. As there are infinitely many solutions, we use the `islice` class from the `itertools` module to trace the search for the first 3 solutions only: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_program = LogicProgram('prolog_ex_2.pl')\n",
    "for _ in islice(trace_solve(logic_program, 'join(X, X, Y)'), 3):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the Prolog interpreter in `LogicProgram` should now be clear. The only addition to the code of the tracing function is that we check that the goals to solve are built from predicate and function symbols that all occur in the logic program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicProgram(LogicProgram):\n",
    "    class QueryError(Exception):\n",
    "        pass\n",
    "\n",
    "    def solve(self, query, depth_first=True):\n",
    "        query = Conjunction.parse_conjunction(query)\n",
    "        if any(predicate_symbol not in self.predicate_symbols\n",
    "               or query.predicate_symbols[predicate_symbol]\n",
    "                  != self.predicate_symbols[predicate_symbol]\n",
    "                      for predicate_symbol in query.predicate_symbols\n",
    "              ):\n",
    "            raise LogicProgram.QueryError(f'Predicate symbol in {query} '\n",
    "                                          'not in program'\n",
    "                                         )\n",
    "        if any(function_symbol not in self.function_symbols\n",
    "               or query.function_symbols[function_symbol]\n",
    "                  != self.function_symbols[function_symbol]\n",
    "                      for function_symbol in query.function_symbols\n",
    "              ):\n",
    "            raise LogicProgram.QueryError(f'Function symbol in {query} '\n",
    "                                           'not in program'\n",
    "                                          )               \n",
    "        query_variables = {var for atom in query for var in atom.variables()}\n",
    "        # A list of pairs consisting of:\n",
    "        # - a list of goals to be solved, and\n",
    "        # - the substitution to apply to the variables that occur in the\n",
    "        #   query as determined by the unifications computed so far.\n",
    "        goals_solution_pairs = deque([(deque(query),\n",
    "                                       {var: Term(var)\n",
    "                                            for var in query_variables\n",
    "                                       }\n",
    "                                      )\n",
    "                                     ]\n",
    "                                    )\n",
    "        while goals_solution_pairs:\n",
    "            goals, solution = goals_solution_pairs.popleft()\n",
    "            if not goals:\n",
    "                yield {var: str(solution[var]) for var in solution}\n",
    "                continue\n",
    "            reserved_variables = query_variables\\\n",
    "                                 | {var for atom in goals\n",
    "                                           for var in atom.variables()\n",
    "                                   }\n",
    "            goal = goals.popleft()\n",
    "            next_goals_solution_pairs = deque()\n",
    "            for rule in self.program:\n",
    "                variable_renaming =\\\n",
    "                        Expression.fresh_variables(rule.variables,\n",
    "                                                   reserved_variables\n",
    "                                                  )\n",
    "                head = rule.head.rename_variables(variable_renaming)\n",
    "                mgu = goal.unify(head)\n",
    "                if mgu is not None:\n",
    "                    new_goals = deque(atom.rename_variables(variable_renaming)\n",
    "                                         .substitute(mgu) for atom in rule.body\n",
    "                                     )\n",
    "                    new_goals.extend(goal.substitute_in_copy(mgu)\n",
    "                                          for goal in goals\n",
    "                                    )\n",
    "                    next_goals_solution_pairs.append(\n",
    "                                   (new_goals,\n",
    "                                    {var: solution[var].substitute_in_copy(mgu)\n",
    "                                         for var in solution\n",
    "                                    }\n",
    "                                   )\n",
    "                                                    )\n",
    "            if depth_first:\n",
    "                goals_solution_pairs.extendleft(\n",
    "                                        reversed(next_goals_solution_pairs)\n",
    "                                               )\n",
    "            else:\n",
    "                goals_solution_pairs.extend(next_goals_solution_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LP = LogicProgram('prolog_ex_1.pl')\n",
    "for solution in LP.solve('grandparent(john, X)'):\n",
    "        print('   ', solution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
